{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e66afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to load all the Libraries and helper functions\n",
    "%run \"Utilities/libraries.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7636b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS TO THE SCRIPTS\n",
    "Bucket_Name=\"model-deploy-poc-new\"\n",
    "\n",
    "train_test_val_location_S3=\"train_test_val\"\n",
    "\n",
    "\n",
    "text_column=\"Article\"\n",
    "target_column=\"Summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6098b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names=\"patrickvonplaten/bert2bert_cnn_daily_mail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cae7db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=boto3.session.Session()\n",
    "role=sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eece75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = f\"s3://{Bucket_Name}/{train_test_val_location_S3}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5403cfe0",
   "metadata": {},
   "source": [
    "## 4. Invoke Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e17d5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# Experiment with your models here. Change hyperparameters to optimize your results\n",
    "def model_invoke(model_name,train_test_val_location_S3):\n",
    "    output_dir_name=model_name.split(\"/\")[-1]\n",
    "    output_path = f\"s3://{Bucket_Name}/model/{output_dir_name}\"\n",
    "    # gets role for executing training job\n",
    "    role = sagemaker.get_execution_role()\n",
    "    hyperparameters = {\n",
    "        \"model-name\": model_name,\n",
    "        \"text-column\": text_column,\n",
    "        \"target-column\": target_column,\n",
    "        \"epoch\": 5,\n",
    "        'train-data-dir':input_path,\n",
    "        'log-dir':output_path+\"/Logs\",\n",
    "        'train-batch-size': 5,\n",
    "        'eval-batch-size': 2,\n",
    "     # more info here https://github.com/huggingface/transformers/tree/v4.17.0/examples/pytorch/summarization\n",
    "    }\n",
    "\n",
    "    metric_definitions = [\n",
    "        {\"Name\": \"training:loss\", \"Regex\": \"'loss': (.*?),\"},\n",
    "        {\"Name\": \"validation:loss\", \"Regex\": \"'eval_loss': (.*?),\"},\n",
    "        {\"Name\": \"validation:rouge1\", \"Regex\": \"'eval_rouge1': (.*?),\"},\n",
    "        {\"Name\": \"validation:rouge2\", \"Regex\": \"'eval_rouge2': (.*?),\"},\n",
    "        {\"Name\": \"validation:rougeL\", \"Regex\": \"'eval_rougeL': (.*?),\"},\n",
    "        {\"Name\": \"validation:rougeLsum\", \"Regex\": \"'eval_rougeLsum': (.*?),\"},\n",
    "        {\"Name\": \"validation:gen_len\", \"Regex\": \"'eval_gen_len': (.*?),\"},\n",
    "    ]\n",
    "\n",
    "    # git configuration to download our fine-tuning script\n",
    "    # git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.17.0'}\n",
    "\n",
    "# creates Hugging Face estimator\n",
    "    huggingface_estimator = HuggingFace(\n",
    "     entry_point='train.py',\n",
    "     source_dir='Utilities',\n",
    "     instance_type='ml.p3.2xlarge',\n",
    "     base_job_name=(model_name.split(\"/\")[-1]).replace(\"_\",\"-\"),   \n",
    "     instance_count=1,\n",
    "     role=role,\n",
    "    #  git_config=git_config,\n",
    "     transformers_version='4.17.0',\n",
    "     pytorch_version='1.10.2',\n",
    "     py_version='py38',\n",
    "     hyperparameters = hyperparameters,\n",
    "     output_path=output_path,\n",
    "#  If operating on ml.p3.4xlarge and above we can opt for distributed computing to reduce training time.\n",
    "#      distribution ={\"mpi\": { \"enabled\": True },\"smdistributed\": {\"modelparallel\": { \"enabled\": True,\"parameters\": {}}}},\n",
    "     metric_definitions=metric_definitions,\n",
    "    )\n",
    "    \n",
    "    huggingface_estimator.fit({\"train\": f\"s3://{Bucket_Name}/{train_test_val_location_S3}/train\",\n",
    "                           \"test\": f\"s3://{Bucket_Name}/{train_test_val_location_S3}/val\"})\n",
    "    return(huggingface_estimator)\n",
    "# starting the train job\n",
    "# huggingface_estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb744d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-03 11:41:42 Starting - Starting the training job...\n",
      "2022-07-03 11:42:05 Starting - Preparing the instances for trainingProfilerReport-1656848501: InProgress\n",
      ".........\n",
      "2022-07-03 11:43:25 Downloading - Downloading input data...\n",
      "2022-07-03 11:44:05 Training - Downloading the training image.......................\n",
      "2022-07-03 11:48:46 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/paramiko/transport.py:236: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\u001b[0m\n",
      "\u001b[34m2022-07-03 11:48:35,969 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-07-03 11:48:35,990 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-07-03 11:48:35,998 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-07-03 11:48:36,803 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting nltk\u001b[0m\n",
      "\u001b[34mDownloading nltk-3.7-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 18.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting rouge_score\u001b[0m\n",
      "\u001b[34mDownloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.8/site-packages (from nltk->-r requirements.txt (line 1)) (2022.4.24)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk->-r requirements.txt (line 1)) (8.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk->-r requirements.txt (line 1)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk->-r requirements.txt (line 1)) (4.63.0)\u001b[0m\n",
      "\u001b[34mCollecting absl-py\u001b[0m\n",
      "\u001b[34mDownloading absl_py-1.1.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.7/123.7 kB 5.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.8/site-packages (from rouge_score->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from rouge_score->-r requirements.txt (line 2)) (1.22.2)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: nltk, absl-py, rouge_score\u001b[0m\n",
      "\u001b[34mSuccessfully installed absl-py-1.1.0 nltk-3.7 rouge_score-0.0.4\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: There was an error checking the latest version of pip.\u001b[0m\n",
      "\u001b[34m2022-07-03 11:48:41,532 asyncio      WARNING  Loop <_UnixSelectorEventLoop running=False closed=True debug=False> that handles pid 21 is closed\u001b[0m\n",
      "\u001b[34m2022-07-03 11:48:41,600 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epoch\": 5,\n",
      "        \"eval-batch-size\": 2,\n",
      "        \"log-dir\": \"s3://model-deploy-poc-new/model/bert2bert_cnn_daily_mail/Logs\",\n",
      "        \"model-name\": \"patrickvonplaten/bert2bert_cnn_daily_mail\",\n",
      "        \"target-column\": \"Summary\",\n",
      "        \"text-column\": \"Article\",\n",
      "        \"train-batch-size\": 5,\n",
      "        \"train-data-dir\": \"s3://model-deploy-poc-new/train_test_val\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"bert2bert-cnn-daily-mail-2022-07-03-11-41-41-700\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://model-deploy-poc-new/bert2bert-cnn-daily-mail-2022-07-03-11-41-41-700/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epoch\":5,\"eval-batch-size\":2,\"log-dir\":\"s3://model-deploy-poc-new/model/bert2bert_cnn_daily_mail/Logs\",\"model-name\":\"patrickvonplaten/bert2bert_cnn_daily_mail\",\"target-column\":\"Summary\",\"text-column\":\"Article\",\"train-batch-size\":5,\"train-data-dir\":\"s3://model-deploy-poc-new/train_test_val\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://model-deploy-poc-new/bert2bert-cnn-daily-mail-2022-07-03-11-41-41-700/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epoch\":5,\"eval-batch-size\":2,\"log-dir\":\"s3://model-deploy-poc-new/model/bert2bert_cnn_daily_mail/Logs\",\"model-name\":\"patrickvonplaten/bert2bert_cnn_daily_mail\",\"target-column\":\"Summary\",\"text-column\":\"Article\",\"train-batch-size\":5,\"train-data-dir\":\"s3://model-deploy-poc-new/train_test_val\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"bert2bert-cnn-daily-mail-2022-07-03-11-41-41-700\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://model-deploy-poc-new/bert2bert-cnn-daily-mail-2022-07-03-11-41-41-700/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epoch\",\"5\",\"--eval-batch-size\",\"2\",\"--log-dir\",\"s3://model-deploy-poc-new/model/bert2bert_cnn_daily_mail/Logs\",\"--model-name\",\"patrickvonplaten/bert2bert_cnn_daily_mail\",\"--target-column\",\"Summary\",\"--text-column\",\"Article\",\"--train-batch-size\",\"5\",\"--train-data-dir\",\"s3://model-deploy-poc-new/train_test_val\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCH=5\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL-BATCH-SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_LOG-DIR=s3://model-deploy-poc-new/model/bert2bert_cnn_daily_mail/Logs\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL-NAME=patrickvonplaten/bert2bert_cnn_daily_mail\u001b[0m\n",
      "\u001b[34mSM_HP_TARGET-COLUMN=Summary\u001b[0m\n",
      "\u001b[34mSM_HP_TEXT-COLUMN=Article\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN-BATCH-SIZE=5\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN-DATA-DIR=s3://model-deploy-poc-new/train_test_val\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220512-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 train.py --epoch 5 --eval-batch-size 2 --log-dir s3://model-deploy-poc-new/model/bert2bert_cnn_daily_mail/Logs --model-name patrickvonplaten/bert2bert_cnn_daily_mail --target-column Summary --text-column Article --train-batch-size 5 --train-data-dir s3://model-deploy-poc-new/train_test_val\u001b[0m\n",
      "\u001b[34m**********************************************************************\n",
      "  Resource #033[93mpunkt#033[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "  #033[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  #033[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "  Attempted to load #033[93mtokenizers/punkt#033[0m\n",
      "  Searched in:\n",
      "    - '/root/nltk_data'\n",
      "    - '/opt/conda/nltk_data'\n",
      "    - '/opt/conda/share/nltk_data'\n",
      "    - '/opt/conda/lib/nltk_data'\n",
      "    - '/usr/share/nltk_data'\n",
      "    - '/usr/local/share/nltk_data'\n",
      "    - '/usr/lib/nltk_data'\n",
      "    - '/usr/local/lib/nltk_data'\u001b[0m\n",
      "\u001b[34m**********************************************************************\u001b[0m\n",
      "\u001b[34m[nltk_data] Downloading package punkt to /root/nltk_data...\u001b[0m\n",
      "\u001b[34m[nltk_data]   Unzipping tokenizers/punkt.zip.\u001b[0m\n",
      "\u001b[34mLoading tokenizer...\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/252 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 252/252 [00:00<00:00, 344kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/3.57k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 3.57k/3.57k [00:00<00:00, 5.02MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 226k/226k [00:00<00:00, 5.19MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/156 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 156/156 [00:00<00:00, 198kB/s]\u001b[0m\n",
      "\u001b[34mLoading pretrained model\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/944M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 768k/944M [00:00<02:05, 7.86MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   1%|          | 5.97M/944M [00:00<00:27, 35.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   1%|          | 11.5M/944M [00:00<00:21, 45.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   2%|▏         | 17.7M/944M [00:00<00:18, 53.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   3%|▎         | 24.0M/944M [00:00<00:16, 58.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   3%|▎         | 30.4M/944M [00:00<00:15, 61.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   4%|▍         | 36.8M/944M [00:00<00:15, 63.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   5%|▍         | 43.2M/944M [00:00<00:14, 64.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   5%|▌         | 49.5M/944M [00:00<00:14, 64.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   6%|▌         | 56.0M/944M [00:01<00:14, 65.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   7%|▋         | 62.3M/944M [00:01<00:13, 66.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   7%|▋         | 68.8M/944M [00:01<00:13, 66.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   8%|▊         | 75.3M/944M [00:01<00:13, 66.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   9%|▊         | 81.8M/944M [00:01<00:13, 67.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   9%|▉         | 88.4M/944M [00:01<00:13, 68.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  10%|█         | 95.0M/944M [00:01<00:13, 68.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  11%|█         | 101M/944M [00:01<00:12, 68.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  11%|█▏        | 108M/944M [00:01<00:12, 68.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  12%|█▏        | 115M/944M [00:01<00:12, 68.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  13%|█▎        | 121M/944M [00:02<00:12, 68.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  14%|█▎        | 128M/944M [00:02<00:12, 68.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  14%|█▍        | 134M/944M [00:02<00:12, 68.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  15%|█▍        | 141M/944M [00:02<00:12, 68.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  16%|█▌        | 148M/944M [00:02<00:12, 68.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  16%|█▋        | 154M/944M [00:02<00:12, 68.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  17%|█▋        | 161M/944M [00:02<00:11, 69.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  18%|█▊        | 167M/944M [00:02<00:11, 68.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  18%|█▊        | 174M/944M [00:02<00:11, 68.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  19%|█▉        | 180M/944M [00:02<00:11, 68.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  20%|█▉        | 187M/944M [00:03<00:11, 68.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  21%|██        | 194M/944M [00:03<00:11, 67.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  21%|██        | 200M/944M [00:03<00:11, 68.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  22%|██▏       | 207M/944M [00:03<00:11, 66.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  23%|██▎       | 213M/944M [00:03<00:11, 67.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  23%|██▎       | 220M/944M [00:03<00:11, 67.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  24%|██▍       | 226M/944M [00:03<00:11, 67.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  25%|██▍       | 233M/944M [00:03<00:10, 68.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  25%|██▌       | 239M/944M [00:03<00:11, 64.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  26%|██▌       | 245M/944M [00:03<00:11, 61.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  27%|██▋       | 251M/944M [00:04<00:12, 59.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  27%|██▋       | 257M/944M [00:04<00:12, 58.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  28%|██▊       | 263M/944M [00:04<00:12, 58.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  29%|██▊       | 269M/944M [00:04<00:11, 60.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  29%|██▉       | 275M/944M [00:04<00:11, 62.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  30%|██▉       | 282M/944M [00:04<00:10, 63.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  31%|███       | 288M/944M [00:04<00:10, 65.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  31%|███▏      | 295M/944M [00:04<00:10, 66.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  32%|███▏      | 302M/944M [00:04<00:10, 67.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  33%|███▎      | 308M/944M [00:04<00:09, 67.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  33%|███▎      | 315M/944M [00:05<00:09, 68.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  34%|███▍      | 321M/944M [00:05<00:09, 68.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  35%|███▍      | 328M/944M [00:05<00:09, 68.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  35%|███▌      | 335M/944M [00:05<00:09, 68.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  36%|███▌      | 341M/944M [00:05<00:09, 69.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  37%|███▋      | 348M/944M [00:05<00:09, 69.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  38%|███▊      | 355M/944M [00:05<00:08, 69.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  38%|███▊      | 361M/944M [00:05<00:08, 70.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  39%|███▉      | 368M/944M [00:05<00:08, 68.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  40%|███▉      | 375M/944M [00:05<00:08, 69.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  40%|████      | 382M/944M [00:06<00:08, 70.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  41%|████      | 388M/944M [00:06<00:08, 70.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  42%|████▏     | 395M/944M [00:06<00:08, 71.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  43%|████▎     | 402M/944M [00:06<00:07, 71.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  43%|████▎     | 409M/944M [00:06<00:07, 71.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  44%|████▍     | 416M/944M [00:06<00:07, 71.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  45%|████▍     | 423M/944M [00:06<00:07, 71.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  46%|████▌     | 430M/944M [00:06<00:07, 74.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  46%|████▋     | 438M/944M [00:06<00:07, 75.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  47%|████▋     | 446M/944M [00:06<00:06, 76.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  48%|████▊     | 453M/944M [00:07<00:06, 78.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  49%|████▉     | 461M/944M [00:07<00:06, 79.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  50%|████▉     | 469M/944M [00:07<00:06, 80.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  51%|█████     | 477M/944M [00:07<00:06, 80.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  51%|█████▏    | 485M/944M [00:07<00:05, 81.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  52%|█████▏    | 492M/944M [00:07<00:05, 81.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  53%|█████▎    | 500M/944M [00:07<00:05, 81.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  54%|█████▍    | 508M/944M [00:07<00:05, 81.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  55%|█████▍    | 516M/944M [00:07<00:05, 81.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  55%|█████▌    | 523M/944M [00:07<00:05, 81.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  56%|█████▋    | 531M/944M [00:08<00:05, 81.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  57%|█████▋    | 539M/944M [00:08<00:05, 81.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  58%|█████▊    | 547M/944M [00:08<00:05, 81.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  59%|█████▉    | 555M/944M [00:08<00:05, 81.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  60%|█████▉    | 562M/944M [00:08<00:04, 81.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  60%|██████    | 570M/944M [00:08<00:04, 81.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  61%|██████▏   | 578M/944M [00:08<00:04, 81.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  62%|██████▏   | 586M/944M [00:08<00:04, 82.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  63%|██████▎   | 594M/944M [00:08<00:04, 81.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  64%|██████▎   | 602M/944M [00:08<00:04, 81.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  65%|██████▍   | 610M/944M [00:09<00:04, 81.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  65%|██████▌   | 617M/944M [00:09<00:04, 81.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  66%|██████▌   | 625M/944M [00:09<00:04, 81.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  67%|██████▋   | 633M/944M [00:09<00:04, 81.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  68%|██████▊   | 641M/944M [00:09<00:04, 75.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  69%|██████▊   | 648M/944M [00:09<00:04, 77.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  69%|██████▉   | 656M/944M [00:09<00:04, 73.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  70%|███████   | 663M/944M [00:09<00:03, 75.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  71%|███████   | 671M/944M [00:09<00:03, 73.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  72%|███████▏  | 678M/944M [00:10<00:04, 66.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  72%|███████▏  | 684M/944M [00:10<00:04, 65.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  73%|███████▎  | 690M/944M [00:10<00:04, 66.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  74%|███████▍  | 697M/944M [00:10<00:04, 64.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  75%|███████▍  | 703M/944M [00:10<00:03, 65.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  75%|███████▌  | 710M/944M [00:10<00:03, 66.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  76%|███████▌  | 716M/944M [00:10<00:03, 67.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  77%|███████▋  | 723M/944M [00:10<00:03, 67.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  77%|███████▋  | 729M/944M [00:10<00:03, 67.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  78%|███████▊  | 736M/944M [00:11<00:03, 64.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  79%|███████▊  | 742M/944M [00:11<00:03, 61.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  79%|███████▉  | 748M/944M [00:11<00:03, 60.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  80%|███████▉  | 754M/944M [00:11<00:03, 59.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  80%|████████  | 759M/944M [00:11<00:03, 59.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  81%|████████  | 766M/944M [00:11<00:03, 61.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  82%|████████▏ | 772M/944M [00:11<00:02, 63.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  83%|████████▎ | 779M/944M [00:11<00:02, 64.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  83%|████████▎ | 785M/944M [00:11<00:02, 65.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  84%|████████▍ | 792M/944M [00:11<00:02, 66.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  85%|████████▍ | 798M/944M [00:12<00:02, 62.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  85%|████████▌ | 804M/944M [00:12<00:02, 62.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  86%|████████▌ | 810M/944M [00:12<00:02, 61.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  86%|████████▋ | 816M/944M [00:12<00:02, 59.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  87%|████████▋ | 822M/944M [00:12<00:02, 56.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  88%|████████▊ | 828M/944M [00:12<00:02, 57.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  88%|████████▊ | 834M/944M [00:12<00:01, 59.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  89%|████████▉ | 839M/944M [00:12<00:01, 59.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  90%|████████▉ | 845M/944M [00:12<00:01, 60.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  90%|█████████ | 851M/944M [00:13<00:01, 61.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  91%|█████████ | 858M/944M [00:13<00:01, 63.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  92%|█████████▏| 864M/944M [00:13<00:01, 64.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  92%|█████████▏| 871M/944M [00:13<00:01, 65.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  93%|█████████▎| 878M/944M [00:13<00:01, 67.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  94%|█████████▎| 884M/944M [00:13<00:01, 42.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  94%|█████████▍| 890M/944M [00:13<00:01, 47.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  95%|█████████▌| 897M/944M [00:13<00:00, 52.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  96%|█████████▌| 903M/944M [00:13<00:00, 55.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  96%|█████████▋| 909M/944M [00:14<00:00, 58.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  97%|█████████▋| 916M/944M [00:14<00:00, 60.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  98%|█████████▊| 922M/944M [00:14<00:00, 62.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  98%|█████████▊| 929M/944M [00:14<00:00, 64.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  99%|█████████▉| 935M/944M [00:14<00:00, 65.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|█████████▉| 942M/944M [00:14<00:00, 67.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 944M/944M [00:14<00:00, 67.7MB/s]\u001b[0m\n",
      "\u001b[34mPretrained model loaded\u001b[0m\n",
      "\u001b[34mFetching and tokenizing data for training\u001b[0m\n",
      "\u001b[34m0%|          | 0/4 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 1/4 [00:00<00:01,  2.11ba/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 2/4 [00:00<00:00,  2.53ba/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 3/4 [00:01<00:00,  2.65ba/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 4/4 [00:01<00:00,  3.18ba/s]\u001b[0m\n",
      "\u001b[34mTokenizing data for training loaded\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 14.69ba/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00,  4.49ba/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00,  4.49ba/s]\u001b[0m\n",
      "\u001b[34mDefining training arguments\u001b[0m\n",
      "\u001b[34mDefining seq2seq Trainer\u001b[0m\n",
      "\u001b[34mStarting Training\u001b[0m\n",
      "\u001b[34mThe following columns in the training set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the training set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m***** Running training *****\u001b[0m\n",
      "\u001b[34mNum examples = 1632\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 1632\u001b[0m\n",
      "\u001b[34mNum Epochs = 5\n",
      "  Instantaneous batch size per device = 5\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 5\u001b[0m\n",
      "\u001b[34mNum Epochs = 5\n",
      "  Instantaneous batch size per device = 5\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 5\u001b[0m\n",
      "\u001b[34mGradient Accumulation steps = 1\n",
      "  Total optimization steps = 1635\u001b[0m\n",
      "\u001b[34mGradient Accumulation steps = 1\n",
      "  Total optimization steps = 1635\u001b[0m\n",
      "\u001b[34m0%|          | 0/1635 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:24.473 algo-1:34 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220512-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220512-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:24.695 algo-1:34 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:24.697 algo-1:34 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:24.697 algo-1:34 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:24.698 algo-1:34 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:24.698 algo-1:34 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.embeddings.word_embeddings.weight count_params:23440896\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.embeddings.position_embeddings.weight count_params:393216\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.embeddings.token_type_embeddings.weight count_params:1536\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.433 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.0.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.434 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.1.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.435 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.2.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.436 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.3.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.437 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.4.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.438 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.5.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.439 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.6.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.440 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.441 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.7.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.442 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.8.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.443 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.9.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.444 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.10.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.445 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:encoder.encoder.layer.11.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:encoder.pooler.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:encoder.pooler.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:decoder.bert.embeddings.word_embeddings.weight count_params:23440896\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:decoder.bert.embeddings.position_embeddings.weight count_params:393216\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.446 algo-1:34 INFO hook.py:560] name:decoder.bert.embeddings.token_type_embeddings.weight count_params:1536\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.447 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.448 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.0.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.449 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.1.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.450 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.451 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.2.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.452 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.3.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.453 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.454 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.4.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.455 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.5.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.456 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.6.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.457 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.458 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.7.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.459 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.460 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.8.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.461 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.462 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.9.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.463 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.10.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.464 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.crossattention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.crossattention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.crossattention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.crossattention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.crossattention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.crossattention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.crossattention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.crossattention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.465 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:560] name:decoder.bert.encoder.layer.11.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:560] name:decoder.cls.predictions.bias count_params:30522\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:560] name:decoder.cls.predictions.transform.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:560] name:decoder.cls.predictions.transform.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:560] name:decoder.cls.predictions.transform.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:560] name:decoder.cls.predictions.transform.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:562] Total Trainable Params: 247363386\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.466 algo-1:34 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-07-03 11:49:25.469 algo-1:34 INFO hook.py:485] Hook is writing from the hook with pid: 34\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\u001b[0m\n",
      "\u001b[34m0%|          | 1/1635 [00:04<1:54:45,  4.21s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/1635 [00:04<55:02,  2.02s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/1635 [00:05<35:28,  1.30s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 4/1635 [00:05<26:23,  1.03it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 5/1635 [00:06<21:40,  1.25it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 6/1635 [00:06<18:31,  1.47it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 7/1635 [00:07<16:49,  1.61it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 8/1635 [00:07<15:29,  1.75it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 9/1635 [00:07<14:19,  1.89it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 10/1635 [00:08<13:31,  2.00it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 11/1635 [00:08<12:58,  2.09it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 12/1635 [00:09<12:41,  2.13it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 13/1635 [00:09<12:38,  2.14it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 14/1635 [00:10<12:30,  2.16it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 15/1635 [00:10<12:22,  2.18it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 16/1635 [00:11<12:15,  2.20it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 17/1635 [00:11<12:16,  2.20it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 18/1635 [00:11<12:09,  2.22it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 19/1635 [00:12<12:05,  2.23it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 20/1635 [00:12<12:02,  2.24it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 21/1635 [00:13<12:02,  2.23it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 22/1635 [00:13<12:05,  2.22it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 23/1635 [00:14<11:57,  2.25it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 24/1635 [00:14<11:55,  2.25it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 25/1635 [00:15<11:52,  2.26it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 26/1635 [00:15<12:33,  2.14it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 27/1635 [00:16<12:21,  2.17it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 28/1635 [00:16<12:10,  2.20it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 29/1635 [00:16<12:11,  2.20it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 30/1635 [00:17<11:58,  2.23it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 31/1635 [00:17<11:51,  2.26it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 32/1635 [00:18<11:42,  2.28it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 33/1635 [00:18<11:45,  2.27it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 34/1635 [00:19<11:50,  2.25it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 35/1635 [00:19<11:46,  2.26it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 36/1635 [00:20<12:00,  2.22it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 37/1635 [00:20<12:04,  2.21it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 38/1635 [00:20<11:58,  2.22it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 39/1635 [00:21<11:49,  2.25it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 40/1635 [00:21<11:45,  2.26it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 41/1635 [00:22<11:42,  2.27it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 42/1635 [00:22<11:48,  2.25it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 43/1635 [00:23<11:55,  2.23it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 44/1635 [00:23<11:57,  2.22it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 45/1635 [00:24<11:48,  2.24it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 46/1635 [00:24<11:40,  2.27it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 47/1635 [00:24<11:37,  2.28it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 48/1635 [00:25<11:33,  2.29it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 49/1635 [00:25<11:39,  2.27it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 50/1635 [00:26<11:36,  2.28it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 51/1635 [00:26<11:34,  2.28it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 52/1635 [00:27<11:33,  2.28it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 53/1635 [00:27<11:31,  2.29it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 54/1635 [00:27<11:32,  2.28it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 55/1635 [00:28<11:32,  2.28it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 56/1635 [00:28<11:33,  2.28it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 57/1635 [00:29<11:27,  2.30it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 58/1635 [00:29<11:29,  2.29it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 59/1635 [00:30<11:35,  2.26it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 60/1635 [00:30<11:31,  2.28it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 61/1635 [00:31<11:26,  2.29it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 62/1635 [00:31<11:24,  2.30it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 63/1635 [00:31<11:21,  2.31it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 64/1635 [00:32<11:21,  2.30it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 65/1635 [00:32<11:26,  2.29it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 66/1635 [00:33<11:28,  2.28it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 67/1635 [00:33<11:22,  2.30it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 68/1635 [00:34<11:17,  2.31it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 69/1635 [00:34<11:19,  2.31it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 70/1635 [00:34<11:23,  2.29it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 71/1635 [00:35<11:21,  2.30it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 72/1635 [00:35<11:25,  2.28it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 73/1635 [00:36<11:22,  2.29it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 74/1635 [00:36<11:39,  2.23it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 75/1635 [00:37<12:04,  2.15it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 76/1635 [00:37<12:02,  2.16it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 77/1635 [00:38<12:14,  2.12it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 78/1635 [00:38<12:18,  2.11it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 79/1635 [00:39<11:59,  2.16it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 80/1635 [00:39<12:19,  2.10it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 81/1635 [00:40<12:46,  2.03it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 82/1635 [00:40<12:20,  2.10it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 83/1635 [00:41<11:59,  2.16it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 84/1635 [00:41<11:45,  2.20it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 85/1635 [00:41<11:52,  2.18it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 86/1635 [00:42<11:46,  2.19it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 87/1635 [00:42<11:32,  2.23it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 88/1635 [00:43<11:26,  2.25it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 89/1635 [00:43<11:20,  2.27it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 90/1635 [00:44<11:18,  2.28it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 91/1635 [00:44<11:21,  2.26it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 92/1635 [00:45<11:38,  2.21it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 93/1635 [00:45<11:39,  2.20it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 94/1635 [00:45<11:35,  2.21it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 95/1635 [00:46<11:32,  2.22it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 96/1635 [00:46<11:24,  2.25it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 97/1635 [00:47<11:27,  2.24it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 98/1635 [00:47<11:29,  2.23it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 99/1635 [00:48<11:23,  2.25it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 100/1635 [00:48<11:19,  2.26it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 101/1635 [00:49<11:24,  2.24it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 102/1635 [00:49<11:24,  2.24it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 103/1635 [00:50<11:56,  2.14it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 104/1635 [00:50<11:44,  2.17it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 105/1635 [00:50<11:34,  2.20it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 106/1635 [00:51<11:26,  2.23it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 107/1635 [00:51<11:16,  2.26it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 108/1635 [00:52<11:15,  2.26it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 109/1635 [00:52<11:08,  2.28it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 110/1635 [00:53<11:02,  2.30it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 111/1635 [00:53<10:58,  2.32it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 112/1635 [00:53<10:54,  2.33it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 113/1635 [00:54<10:52,  2.33it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 114/1635 [00:54<10:58,  2.31it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 115/1635 [00:55<11:17,  2.24it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 116/1635 [00:55<11:11,  2.26it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 117/1635 [00:56<11:11,  2.26it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 118/1635 [00:56<11:15,  2.24it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 119/1635 [00:57<11:06,  2.28it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 120/1635 [00:57<11:05,  2.28it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 121/1635 [00:57<11:01,  2.29it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 122/1635 [00:58<10:59,  2.29it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 123/1635 [00:58<11:08,  2.26it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 124/1635 [00:59<11:21,  2.22it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 125/1635 [00:59<11:12,  2.24it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 126/1635 [01:00<11:14,  2.24it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 127/1635 [01:00<11:10,  2.25it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 128/1635 [01:01<11:05,  2.26it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 129/1635 [01:01<10:59,  2.28it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 130/1635 [01:01<10:53,  2.30it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 131/1635 [01:02<10:49,  2.32it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 132/1635 [01:02<10:57,  2.29it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 133/1635 [01:03<10:57,  2.29it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 134/1635 [01:03<11:05,  2.26it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 135/1635 [01:04<11:00,  2.27it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 136/1635 [01:04<10:53,  2.29it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 137/1635 [01:04<10:50,  2.30it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 138/1635 [01:05<10:53,  2.29it/s]\u001b[0m\n",
      "\u001b[34m9%|▊         | 139/1635 [01:05<10:47,  2.31it/s]\u001b[0m\n",
      "\u001b[34m9%|▊         | 140/1635 [01:06<10:43,  2.32it/s]\u001b[0m\n",
      "\u001b[34m9%|▊         | 141/1635 [01:06<10:55,  2.28it/s]\u001b[0m\n",
      "\u001b[34m9%|▊         | 142/1635 [01:07<10:50,  2.30it/s]\u001b[0m\n",
      "\u001b[34m9%|▊         | 143/1635 [01:07<10:57,  2.27it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 144/1635 [01:07<10:59,  2.26it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 145/1635 [01:08<11:07,  2.23it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 146/1635 [01:08<11:04,  2.24it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 147/1635 [01:09<11:01,  2.25it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 148/1635 [01:09<10:56,  2.27it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 149/1635 [01:10<10:54,  2.27it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 150/1635 [01:10<10:55,  2.26it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 151/1635 [01:11<10:50,  2.28it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 152/1635 [01:11<11:01,  2.24it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 153/1635 [01:11<10:53,  2.27it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 154/1635 [01:12<10:56,  2.25it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 155/1635 [01:12<10:53,  2.26it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 156/1635 [01:13<11:03,  2.23it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 157/1635 [01:13<10:57,  2.25it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 158/1635 [01:14<10:53,  2.26it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 159/1635 [01:14<10:46,  2.28it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 160/1635 [01:15<11:06,  2.21it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 161/1635 [01:15<11:06,  2.21it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 162/1635 [01:16<11:05,  2.21it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 163/1635 [01:16<11:16,  2.18it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 164/1635 [01:16<11:15,  2.18it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 165/1635 [01:17<11:05,  2.21it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 166/1635 [01:17<11:05,  2.21it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 167/1635 [01:18<11:01,  2.22it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 168/1635 [01:18<10:54,  2.24it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 169/1635 [01:19<11:06,  2.20it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 170/1635 [01:19<11:04,  2.21it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 171/1635 [01:20<11:06,  2.20it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 172/1635 [01:20<11:04,  2.20it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 173/1635 [01:21<10:58,  2.22it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 174/1635 [01:21<10:56,  2.22it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 175/1635 [01:21<10:54,  2.23it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 176/1635 [01:22<10:53,  2.23it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 177/1635 [01:22<10:53,  2.23it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 178/1635 [01:23<10:49,  2.24it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 179/1635 [01:23<10:48,  2.25it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 180/1635 [01:24<11:28,  2.11it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 181/1635 [01:24<11:18,  2.14it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 182/1635 [01:25<11:08,  2.17it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 183/1635 [01:25<11:11,  2.16it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 184/1635 [01:26<11:02,  2.19it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 185/1635 [01:26<10:55,  2.21it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 186/1635 [01:26<10:56,  2.21it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 187/1635 [01:27<10:52,  2.22it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 188/1635 [01:27<10:52,  2.22it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 189/1635 [01:28<10:50,  2.22it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 190/1635 [01:28<10:47,  2.23it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 191/1635 [01:29<10:44,  2.24it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 192/1635 [01:29<10:49,  2.22it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 193/1635 [01:30<10:49,  2.22it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 194/1635 [01:30<10:46,  2.23it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 195/1635 [01:30<10:43,  2.24it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 196/1635 [01:31<10:41,  2.24it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 197/1635 [01:31<10:59,  2.18it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 198/1635 [01:32<10:52,  2.20it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 199/1635 [01:32<10:47,  2.22it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 200/1635 [01:33<10:44,  2.23it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 201/1635 [01:33<10:37,  2.25it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 202/1635 [01:34<10:33,  2.26it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 203/1635 [01:34<10:36,  2.25it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 204/1635 [01:34<10:33,  2.26it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 205/1635 [01:35<10:30,  2.27it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 206/1635 [01:35<10:40,  2.23it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 207/1635 [01:36<10:34,  2.25it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 208/1635 [01:36<10:33,  2.25it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 209/1635 [01:37<10:30,  2.26it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 210/1635 [01:37<10:44,  2.21it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 211/1635 [01:38<10:56,  2.17it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 212/1635 [01:38<11:10,  2.12it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 213/1635 [01:39<11:03,  2.14it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 214/1635 [01:39<11:17,  2.10it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 215/1635 [01:40<11:34,  2.04it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 216/1635 [01:40<11:32,  2.05it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 217/1635 [01:41<11:10,  2.12it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 218/1635 [01:41<10:58,  2.15it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 219/1635 [01:41<10:59,  2.15it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 220/1635 [01:42<10:48,  2.18it/s]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 221/1635 [01:42<10:40,  2.21it/s]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 222/1635 [01:43<10:46,  2.19it/s]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 223/1635 [01:43<10:39,  2.21it/s]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 224/1635 [01:44<10:36,  2.22it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 225/1635 [01:44<10:32,  2.23it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 226/1635 [01:45<10:39,  2.20it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 227/1635 [01:45<10:43,  2.19it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 228/1635 [01:46<10:41,  2.19it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 229/1635 [01:46<10:40,  2.19it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 230/1635 [01:46<10:49,  2.16it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 231/1635 [01:47<10:40,  2.19it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 232/1635 [01:47<10:32,  2.22it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 233/1635 [01:48<10:26,  2.24it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 234/1635 [01:48<10:27,  2.23it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 235/1635 [01:49<10:24,  2.24it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 236/1635 [01:49<10:22,  2.25it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 237/1635 [01:50<10:29,  2.22it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 238/1635 [01:50<10:28,  2.22it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 239/1635 [01:50<10:24,  2.24it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 240/1635 [01:51<10:23,  2.24it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 241/1635 [01:51<10:14,  2.27it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 242/1635 [01:52<10:10,  2.28it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 243/1635 [01:52<10:07,  2.29it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 244/1635 [01:53<10:04,  2.30it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 245/1635 [01:53<10:12,  2.27it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 246/1635 [01:54<10:10,  2.28it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 247/1635 [01:54<10:11,  2.27it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 248/1635 [01:54<10:12,  2.27it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 249/1635 [01:55<10:18,  2.24it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 250/1635 [01:55<10:13,  2.26it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 251/1635 [01:56<10:11,  2.26it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 252/1635 [01:56<10:06,  2.28it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 253/1635 [01:57<10:04,  2.29it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 254/1635 [01:57<10:04,  2.28it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 255/1635 [01:57<10:04,  2.28it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 256/1635 [01:58<10:04,  2.28it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 257/1635 [01:58<10:39,  2.15it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 258/1635 [01:59<10:33,  2.17it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 259/1635 [01:59<10:28,  2.19it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 260/1635 [02:00<10:20,  2.21it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 261/1635 [02:00<10:18,  2.22it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 262/1635 [02:01<10:20,  2.21it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 263/1635 [02:01<10:13,  2.24it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 264/1635 [02:02<10:11,  2.24it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 265/1635 [02:02<10:03,  2.27it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 266/1635 [02:02<09:58,  2.29it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 267/1635 [02:03<09:58,  2.29it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 268/1635 [02:03<09:55,  2.30it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 269/1635 [02:04<09:55,  2.30it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 270/1635 [02:04<09:51,  2.31it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 271/1635 [02:05<09:54,  2.29it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 272/1635 [02:05<09:57,  2.28it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 273/1635 [02:05<09:54,  2.29it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 274/1635 [02:06<09:55,  2.29it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 275/1635 [02:06<09:54,  2.29it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 276/1635 [02:07<09:53,  2.29it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 277/1635 [02:07<09:53,  2.29it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 278/1635 [02:08<09:51,  2.30it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 279/1635 [02:08<10:00,  2.26it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 280/1635 [02:09<09:59,  2.26it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 281/1635 [02:09<09:57,  2.27it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 282/1635 [02:09<09:58,  2.26it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 283/1635 [02:10<10:01,  2.25it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 284/1635 [02:10<09:56,  2.27it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 285/1635 [02:11<09:52,  2.28it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 286/1635 [02:11<09:54,  2.27it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 287/1635 [02:12<09:50,  2.28it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 288/1635 [02:12<09:51,  2.28it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 289/1635 [02:13<09:50,  2.28it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 290/1635 [02:13<09:53,  2.27it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 291/1635 [02:13<09:58,  2.24it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 292/1635 [02:14<09:52,  2.27it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 293/1635 [02:14<10:07,  2.21it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 294/1635 [02:15<10:06,  2.21it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 295/1635 [02:15<10:05,  2.21it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 296/1635 [02:16<10:13,  2.18it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 297/1635 [02:16<10:05,  2.21it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 298/1635 [02:17<09:59,  2.23it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 299/1635 [02:17<09:54,  2.25it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 300/1635 [02:17<09:54,  2.25it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 301/1635 [02:18<09:56,  2.24it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 302/1635 [02:18<09:50,  2.26it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 303/1635 [02:19<09:48,  2.26it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 304/1635 [02:19<10:00,  2.22it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 305/1635 [02:20<09:54,  2.24it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 306/1635 [02:20<09:56,  2.23it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 307/1635 [02:21<09:49,  2.25it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 308/1635 [02:21<09:53,  2.24it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 309/1635 [02:21<09:46,  2.26it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 310/1635 [02:22<09:41,  2.28it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 311/1635 [02:22<09:39,  2.29it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 312/1635 [02:23<09:36,  2.29it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 313/1635 [02:23<09:32,  2.31it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 314/1635 [02:24<09:31,  2.31it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 315/1635 [02:24<09:33,  2.30it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 316/1635 [02:24<09:31,  2.31it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 317/1635 [02:25<09:42,  2.26it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 318/1635 [02:25<09:42,  2.26it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 319/1635 [02:26<09:45,  2.25it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 320/1635 [02:26<09:43,  2.25it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 321/1635 [02:27<09:36,  2.28it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 322/1635 [02:27<09:34,  2.28it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 323/1635 [02:28<09:33,  2.29it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 324/1635 [02:28<09:34,  2.28it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 325/1635 [02:28<09:37,  2.27it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 326/1635 [02:29<09:37,  2.27it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 327/1635 [02:29<09:29,  2.30it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1493, 'learning_rate': 1.3080000000000002e-05, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m20%|██        | 327/1635 [02:29<09:29,  2.30it/s]\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 82\u001b[0m\n",
      "\u001b[34mNum examples = 82\n",
      "  Batch size = 2\u001b[0m\n",
      "\u001b[34mBatch size = 2\u001b[0m\n",
      "\u001b[34m0%|          | 0/41 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m5%|▍         | 2/41 [00:03<01:11,  1.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m7%|▋         | 3/41 [00:07<01:38,  2.59s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 4/41 [00:10<01:44,  2.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 5/41 [00:14<01:49,  3.05s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▍        | 6/41 [00:17<01:51,  3.18s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 7/41 [00:21<01:52,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m20%|█▉        | 8/41 [00:24<01:50,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 9/41 [00:27<01:47,  3.36s/it]#033[A\u001b[0m\n",
      "\u001b[34m24%|██▍       | 10/41 [00:31<01:44,  3.37s/it]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 11/41 [00:34<01:41,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▉       | 12/41 [00:38<01:42,  3.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m32%|███▏      | 13/41 [00:41<01:37,  3.48s/it]#033[A\u001b[0m\n",
      "\u001b[34m34%|███▍      | 14/41 [00:45<01:35,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 15/41 [00:48<01:30,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 16/41 [00:52<01:25,  3.41s/it]#033[A\u001b[0m\n",
      "\u001b[34m41%|████▏     | 17/41 [00:55<01:24,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 18/41 [00:59<01:20,  3.51s/it]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▋     | 19/41 [01:02<01:15,  3.42s/it]#033[A\u001b[0m\n",
      "\u001b[34m49%|████▉     | 20/41 [01:06<01:12,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m51%|█████     | 21/41 [01:10<01:12,  3.61s/it]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 22/41 [01:13<01:06,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 23/41 [01:16<01:02,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 24/41 [01:20<00:58,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 25/41 [01:23<00:54,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 26/41 [01:26<00:50,  3.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 27/41 [01:30<00:47,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 28/41 [01:33<00:44,  3.41s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 29/41 [01:37<00:41,  3.42s/it]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 30/41 [01:40<00:37,  3.40s/it]#033[A\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 31/41 [01:44<00:34,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 32/41 [01:47<00:30,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m80%|████████  | 33/41 [01:51<00:28,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 34/41 [01:55<00:26,  3.76s/it]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 35/41 [01:59<00:22,  3.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 36/41 [02:02<00:18,  3.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m90%|█████████ | 37/41 [02:06<00:15,  3.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 38/41 [02:10<00:11,  3.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 39/41 [02:13<00:07,  3.67s/it]#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 40/41 [02:17<00:03,  3.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 41/41 [02:20<00:00,  3.61s/it]#033[A\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/2.16k [00:00<?, ?B/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading: 5.60kB [00:00, 4.02MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.6820159554481506, 'eval_rouge1': 45.8867, 'eval_rouge2': 28.3795, 'eval_rougeL': 32.5646, 'eval_rougeLsum': 32.5597, 'eval_gen_len': 78.5854, 'eval_runtime': 145.9467, 'eval_samples_per_second': 0.562, 'eval_steps_per_second': 0.281, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m20%|██        | 327/1635 [04:55<09:29,  2.30it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 41/41 [02:22<00:00,  3.61s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-327\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-327\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-327/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-327/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-327/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-327/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-327/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-327/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-327/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-327/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\u001b[0m\n",
      "\u001b[34m20%|██        | 328/1635 [04:57<16:14:42, 44.75s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 329/1635 [04:58<11:24:37, 31.45s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 330/1635 [04:58<8:01:40, 22.15s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 331/1635 [04:59<5:39:54, 15.64s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 332/1635 [04:59<4:00:33, 11.08s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 333/1635 [05:00<2:51:05,  7.88s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 334/1635 [05:00<2:02:32,  5.65s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 335/1635 [05:01<1:28:35,  4.09s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 336/1635 [05:01<1:04:56,  3.00s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 337/1635 [05:01<48:19,  2.23s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 338/1635 [05:02<36:44,  1.70s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 339/1635 [05:02<28:31,  1.32s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 340/1635 [05:03<22:44,  1.05s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 341/1635 [05:03<18:43,  1.15it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 342/1635 [05:04<16:04,  1.34it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 343/1635 [05:04<14:10,  1.52it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 344/1635 [05:05<13:00,  1.65it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 345/1635 [05:05<11:57,  1.80it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 346/1635 [05:05<11:15,  1.91it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 347/1635 [05:06<10:45,  2.00it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 348/1635 [05:06<10:22,  2.07it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 349/1635 [05:07<10:08,  2.11it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 350/1635 [05:07<09:56,  2.15it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 351/1635 [05:08<09:51,  2.17it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 352/1635 [05:08<09:44,  2.19it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 353/1635 [05:09<09:37,  2.22it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 354/1635 [05:09<09:34,  2.23it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 355/1635 [05:10<09:31,  2.24it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 356/1635 [05:10<09:31,  2.24it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 357/1635 [05:10<09:26,  2.26it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 358/1635 [05:11<09:23,  2.27it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 359/1635 [05:11<09:21,  2.27it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 360/1635 [05:12<09:19,  2.28it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 361/1635 [05:12<09:17,  2.28it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 362/1635 [05:13<09:16,  2.29it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 363/1635 [05:13<09:18,  2.28it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 364/1635 [05:13<09:16,  2.28it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 365/1635 [05:14<09:16,  2.28it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 366/1635 [05:14<09:20,  2.27it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 367/1635 [05:15<09:35,  2.20it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 368/1635 [05:15<09:31,  2.22it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 369/1635 [05:16<09:36,  2.20it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 370/1635 [05:16<09:33,  2.20it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 371/1635 [05:17<09:26,  2.23it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 372/1635 [05:17<09:28,  2.22it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 373/1635 [05:17<09:19,  2.25it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 374/1635 [05:18<09:16,  2.27it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 375/1635 [05:18<09:12,  2.28it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 376/1635 [05:19<09:10,  2.29it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 377/1635 [05:19<09:17,  2.25it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 378/1635 [05:20<09:24,  2.23it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 379/1635 [05:20<09:24,  2.22it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 380/1635 [05:21<09:16,  2.25it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 381/1635 [05:21<09:11,  2.28it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 382/1635 [05:21<09:07,  2.29it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 383/1635 [05:22<09:17,  2.25it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 384/1635 [05:22<09:24,  2.22it/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 385/1635 [05:23<09:23,  2.22it/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 386/1635 [05:23<09:15,  2.25it/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 387/1635 [05:24<09:12,  2.26it/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 388/1635 [05:24<09:18,  2.23it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 389/1635 [05:25<09:14,  2.25it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 390/1635 [05:25<09:12,  2.25it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 391/1635 [05:25<09:15,  2.24it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 392/1635 [05:26<09:21,  2.21it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 393/1635 [05:26<09:21,  2.21it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 394/1635 [05:27<09:20,  2.21it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 395/1635 [05:27<09:20,  2.21it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 396/1635 [05:28<09:49,  2.10it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 397/1635 [05:28<09:42,  2.12it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 398/1635 [05:29<09:32,  2.16it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 399/1635 [05:29<09:28,  2.18it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 400/1635 [05:30<09:33,  2.15it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 401/1635 [05:30<09:28,  2.17it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 402/1635 [05:31<09:26,  2.18it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 403/1635 [05:31<09:29,  2.16it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 404/1635 [05:32<09:27,  2.17it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 405/1635 [05:32<09:32,  2.15it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 406/1635 [05:32<09:31,  2.15it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 407/1635 [05:33<09:28,  2.16it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 408/1635 [05:33<09:24,  2.17it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 409/1635 [05:34<09:17,  2.20it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 410/1635 [05:34<09:16,  2.20it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 411/1635 [05:35<09:17,  2.19it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 412/1635 [05:35<09:17,  2.19it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 413/1635 [05:36<09:13,  2.21it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 414/1635 [05:36<09:17,  2.19it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 415/1635 [05:37<09:16,  2.19it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 416/1635 [05:37<09:10,  2.21it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 417/1635 [05:37<09:18,  2.18it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 418/1635 [05:38<09:21,  2.17it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 419/1635 [05:38<09:22,  2.16it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 420/1635 [05:39<09:18,  2.17it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 421/1635 [05:39<09:16,  2.18it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 422/1635 [05:40<09:13,  2.19it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 423/1635 [05:40<09:10,  2.20it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 424/1635 [05:41<09:22,  2.15it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 425/1635 [05:41<09:20,  2.16it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 426/1635 [05:42<09:31,  2.12it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 427/1635 [05:42<09:52,  2.04it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 428/1635 [05:43<09:44,  2.06it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 429/1635 [05:43<09:36,  2.09it/s]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 430/1635 [05:44<09:26,  2.13it/s]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 431/1635 [05:44<09:15,  2.17it/s]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 432/1635 [05:44<09:03,  2.21it/s]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 433/1635 [05:45<08:54,  2.25it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 434/1635 [05:45<08:50,  2.26it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 435/1635 [05:46<08:44,  2.29it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 436/1635 [05:46<08:48,  2.27it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 437/1635 [05:47<08:50,  2.26it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 438/1635 [05:47<08:46,  2.27it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 439/1635 [05:47<08:42,  2.29it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 440/1635 [05:48<08:45,  2.27it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 441/1635 [05:48<08:48,  2.26it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 442/1635 [05:49<09:00,  2.21it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 443/1635 [05:49<08:59,  2.21it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 444/1635 [05:50<08:53,  2.23it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 445/1635 [05:50<08:45,  2.26it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 446/1635 [05:51<08:43,  2.27it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 447/1635 [05:51<08:46,  2.26it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 448/1635 [05:51<08:42,  2.27it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 449/1635 [05:52<08:43,  2.27it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 450/1635 [05:52<08:43,  2.26it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 451/1635 [05:53<08:37,  2.29it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 452/1635 [05:53<08:35,  2.30it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 453/1635 [05:54<08:32,  2.31it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 454/1635 [05:54<08:39,  2.27it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 455/1635 [05:55<08:37,  2.28it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 456/1635 [05:55<08:34,  2.29it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 457/1635 [05:55<08:35,  2.28it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 458/1635 [05:56<08:39,  2.27it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 459/1635 [05:56<08:37,  2.27it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 460/1635 [05:57<08:40,  2.26it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 461/1635 [05:57<08:38,  2.27it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 462/1635 [05:58<08:33,  2.28it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 463/1635 [05:58<08:28,  2.30it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 464/1635 [05:59<08:32,  2.29it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 465/1635 [05:59<08:28,  2.30it/s]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 466/1635 [05:59<08:30,  2.29it/s]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 467/1635 [06:00<08:25,  2.31it/s]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 468/1635 [06:00<08:29,  2.29it/s]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 469/1635 [06:01<08:29,  2.29it/s]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 470/1635 [06:01<08:33,  2.27it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 471/1635 [06:02<08:37,  2.25it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 472/1635 [06:02<08:38,  2.25it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 473/1635 [06:03<09:07,  2.12it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 474/1635 [06:03<08:56,  2.16it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 475/1635 [06:03<08:49,  2.19it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 476/1635 [06:04<08:44,  2.21it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 477/1635 [06:04<08:41,  2.22it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 478/1635 [06:05<08:38,  2.23it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 479/1635 [06:05<08:41,  2.22it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 480/1635 [06:06<08:54,  2.16it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 481/1635 [06:06<08:50,  2.17it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 482/1635 [06:07<08:45,  2.20it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 483/1635 [06:07<08:36,  2.23it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 484/1635 [06:08<08:39,  2.22it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 485/1635 [06:08<08:39,  2.21it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 486/1635 [06:08<08:32,  2.24it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 487/1635 [06:09<08:28,  2.26it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 488/1635 [06:09<08:25,  2.27it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 489/1635 [06:10<08:30,  2.24it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 490/1635 [06:10<08:26,  2.26it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 491/1635 [06:11<08:27,  2.26it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 492/1635 [06:11<08:23,  2.27it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 493/1635 [06:11<08:18,  2.29it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 494/1635 [06:12<08:28,  2.25it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 495/1635 [06:12<08:41,  2.18it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 496/1635 [06:13<08:41,  2.18it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 497/1635 [06:13<08:37,  2.20it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 498/1635 [06:14<08:40,  2.19it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 499/1635 [06:14<08:51,  2.14it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 500/1635 [06:15<08:57,  2.11it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 501/1635 [06:15<08:47,  2.15it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 502/1635 [06:16<08:48,  2.14it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 503/1635 [06:16<08:44,  2.16it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 504/1635 [06:17<08:43,  2.16it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 505/1635 [06:17<08:47,  2.14it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 506/1635 [06:18<08:40,  2.17it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 507/1635 [06:18<08:35,  2.19it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 508/1635 [06:18<08:31,  2.20it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 509/1635 [06:19<08:31,  2.20it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 510/1635 [06:19<08:34,  2.19it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 511/1635 [06:20<08:42,  2.15it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 512/1635 [06:20<08:45,  2.14it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 513/1635 [06:21<08:35,  2.18it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 514/1635 [06:21<08:26,  2.21it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 515/1635 [06:22<08:20,  2.24it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 516/1635 [06:22<08:14,  2.26it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 517/1635 [06:22<08:13,  2.27it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 518/1635 [06:23<08:13,  2.26it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 519/1635 [06:23<08:13,  2.26it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 520/1635 [06:24<08:13,  2.26it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 521/1635 [06:24<08:10,  2.27it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 522/1635 [06:25<08:10,  2.27it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 523/1635 [06:25<08:10,  2.27it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 524/1635 [06:26<08:08,  2.28it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 525/1635 [06:26<08:05,  2.29it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 526/1635 [06:26<08:07,  2.28it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 527/1635 [06:27<08:16,  2.23it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 528/1635 [06:27<08:28,  2.18it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 529/1635 [06:28<08:26,  2.18it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 530/1635 [06:28<08:25,  2.19it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 531/1635 [06:29<08:24,  2.19it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 532/1635 [06:29<08:26,  2.18it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 533/1635 [06:30<08:30,  2.16it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 534/1635 [06:30<08:24,  2.18it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 535/1635 [06:31<08:22,  2.19it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 536/1635 [06:31<08:22,  2.19it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 537/1635 [06:32<08:21,  2.19it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 538/1635 [06:32<08:18,  2.20it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 539/1635 [06:32<08:13,  2.22it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 540/1635 [06:33<08:11,  2.23it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 541/1635 [06:33<08:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 542/1635 [06:34<08:06,  2.24it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 543/1635 [06:34<08:05,  2.25it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 544/1635 [06:35<08:06,  2.24it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 545/1635 [06:35<08:10,  2.22it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 546/1635 [06:36<08:10,  2.22it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 547/1635 [06:36<08:08,  2.23it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 548/1635 [06:36<08:09,  2.22it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 549/1635 [06:37<08:17,  2.18it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 550/1635 [06:37<08:40,  2.08it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 551/1635 [06:38<08:40,  2.08it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 552/1635 [06:38<08:58,  2.01it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 553/1635 [06:39<08:40,  2.08it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 554/1635 [06:39<08:49,  2.04it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 555/1635 [06:40<08:49,  2.04it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 556/1635 [06:40<08:32,  2.11it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 557/1635 [06:41<08:28,  2.12it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 558/1635 [06:41<08:16,  2.17it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 559/1635 [06:42<08:22,  2.14it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 560/1635 [06:42<08:13,  2.18it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 561/1635 [06:43<08:06,  2.21it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 562/1635 [06:43<08:04,  2.21it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 563/1635 [06:43<07:58,  2.24it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 564/1635 [06:44<07:54,  2.26it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 565/1635 [06:44<07:51,  2.27it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 566/1635 [06:45<07:48,  2.28it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 567/1635 [06:45<07:48,  2.28it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 568/1635 [06:46<07:52,  2.26it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 569/1635 [06:46<07:52,  2.26it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 570/1635 [06:47<07:48,  2.27it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 571/1635 [06:47<07:45,  2.29it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 572/1635 [06:47<07:54,  2.24it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 573/1635 [06:48<07:48,  2.27it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 574/1635 [06:48<07:48,  2.27it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 575/1635 [06:49<07:45,  2.28it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 576/1635 [06:49<07:49,  2.26it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 577/1635 [06:50<07:51,  2.24it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 578/1635 [06:50<08:02,  2.19it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 579/1635 [06:51<08:08,  2.16it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 580/1635 [06:51<07:59,  2.20it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 581/1635 [06:51<07:53,  2.22it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 582/1635 [06:52<07:57,  2.20it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 583/1635 [06:52<07:52,  2.23it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 584/1635 [06:53<07:46,  2.25it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 585/1635 [06:53<07:45,  2.26it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 586/1635 [06:54<07:54,  2.21it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 587/1635 [06:54<07:58,  2.19it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 588/1635 [06:55<07:53,  2.21it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 589/1635 [06:55<07:53,  2.21it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 590/1635 [06:56<07:51,  2.22it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 591/1635 [06:56<07:46,  2.24it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 592/1635 [06:56<07:45,  2.24it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 593/1635 [06:57<07:42,  2.25it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 594/1635 [06:57<07:48,  2.22it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 595/1635 [06:58<07:51,  2.21it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 596/1635 [06:58<07:57,  2.18it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 597/1635 [06:59<08:02,  2.15it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 598/1635 [06:59<07:59,  2.16it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 599/1635 [07:00<07:57,  2.17it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 600/1635 [07:00<07:50,  2.20it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 601/1635 [07:01<07:45,  2.22it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 602/1635 [07:01<07:40,  2.25it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 603/1635 [07:01<07:36,  2.26it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 604/1635 [07:02<07:45,  2.21it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 605/1635 [07:02<07:47,  2.20it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 606/1635 [07:03<07:56,  2.16it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 607/1635 [07:03<07:54,  2.17it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 608/1635 [07:04<07:57,  2.15it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 609/1635 [07:04<07:56,  2.15it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 610/1635 [07:05<07:55,  2.16it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 611/1635 [07:05<07:44,  2.20it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 612/1635 [07:06<07:40,  2.22it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 613/1635 [07:06<07:42,  2.21it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 614/1635 [07:06<07:38,  2.23it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 615/1635 [07:07<07:32,  2.26it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 616/1635 [07:07<07:29,  2.26it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 617/1635 [07:08<07:27,  2.28it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 618/1635 [07:08<07:23,  2.29it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 619/1635 [07:09<07:20,  2.30it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 620/1635 [07:09<07:20,  2.31it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 621/1635 [07:09<07:23,  2.29it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 622/1635 [07:10<07:22,  2.29it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 623/1635 [07:10<07:23,  2.28it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 624/1635 [07:11<07:23,  2.28it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 625/1635 [07:11<07:20,  2.29it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 626/1635 [07:12<07:19,  2.30it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 627/1635 [07:12<07:43,  2.17it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 628/1635 [07:13<07:39,  2.19it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 629/1635 [07:13<07:37,  2.20it/s]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 630/1635 [07:14<07:31,  2.23it/s]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 631/1635 [07:14<07:28,  2.24it/s]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 632/1635 [07:14<07:30,  2.23it/s]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 633/1635 [07:15<07:26,  2.24it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 634/1635 [07:15<07:25,  2.25it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 635/1635 [07:16<07:24,  2.25it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 636/1635 [07:16<07:31,  2.21it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 637/1635 [07:17<07:29,  2.22it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 638/1635 [07:17<07:26,  2.23it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 639/1635 [07:18<07:23,  2.25it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 640/1635 [07:18<07:28,  2.22it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 641/1635 [07:18<07:27,  2.22it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 642/1635 [07:19<07:24,  2.23it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 643/1635 [07:19<07:30,  2.20it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 644/1635 [07:20<07:34,  2.18it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 645/1635 [07:20<07:29,  2.20it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 646/1635 [07:21<07:27,  2.21it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 647/1635 [07:21<07:26,  2.21it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 648/1635 [07:22<07:23,  2.23it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 649/1635 [07:22<07:17,  2.25it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 650/1635 [07:22<07:13,  2.27it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 651/1635 [07:23<07:12,  2.27it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 652/1635 [07:23<07:08,  2.29it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 653/1635 [07:24<07:06,  2.30it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 654/1635 [07:24<06:48,  2.40it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6102, 'learning_rate': 1.7286343612334804e-05, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m40%|████      | 654/1635 [07:24<06:48,  2.40it/s]\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 82\u001b[0m\n",
      "\u001b[34mNum examples = 82\n",
      "  Batch size = 2\u001b[0m\n",
      "\u001b[34mBatch size = 2\u001b[0m\n",
      "\u001b[34m0%|          | 0/41 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m5%|▍         | 2/41 [00:03<01:09,  1.77s/it]#033[A\u001b[0m\n",
      "\u001b[34m7%|▋         | 3/41 [00:07<01:36,  2.53s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 4/41 [00:11<01:52,  3.04s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 5/41 [00:14<01:56,  3.24s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▍        | 6/41 [00:18<01:59,  3.40s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 7/41 [00:21<01:56,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m20%|█▉        | 8/41 [00:25<01:54,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 9/41 [00:28<01:51,  3.49s/it]#033[A\u001b[0m\n",
      "\u001b[34m24%|██▍       | 10/41 [00:32<01:48,  3.51s/it]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 11/41 [00:36<01:46,  3.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▉       | 12/41 [00:39<01:42,  3.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m32%|███▏      | 13/41 [00:43<01:39,  3.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m34%|███▍      | 14/41 [00:46<01:36,  3.56s/it]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 15/41 [00:50<01:32,  3.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 16/41 [00:53<01:28,  3.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m41%|████▏     | 17/41 [00:57<01:25,  3.56s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 18/41 [01:01<01:21,  3.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▋     | 19/41 [01:04<01:18,  3.58s/it]#033[A\u001b[0m\n",
      "\u001b[34m49%|████▉     | 20/41 [01:08<01:15,  3.61s/it]#033[A\u001b[0m\n",
      "\u001b[34m51%|█████     | 21/41 [01:12<01:13,  3.68s/it]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 22/41 [01:15<01:09,  3.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 23/41 [01:19<01:05,  3.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 24/41 [01:23<01:01,  3.64s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 25/41 [01:26<00:58,  3.64s/it]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 26/41 [01:30<00:54,  3.62s/it]#033[A\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 27/41 [01:33<00:50,  3.60s/it]#033[A\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 28/41 [01:37<00:46,  3.59s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 29/41 [01:40<00:42,  3.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 30/41 [01:44<00:39,  3.59s/it]#033[A\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 31/41 [01:48<00:35,  3.56s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 32/41 [01:51<00:32,  3.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m80%|████████  | 33/41 [01:55<00:28,  3.61s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 34/41 [01:59<00:25,  3.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 35/41 [02:02<00:22,  3.68s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 36/41 [02:06<00:18,  3.61s/it]#033[A\u001b[0m\n",
      "\u001b[34m90%|█████████ | 37/41 [02:09<00:14,  3.62s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 38/41 [02:13<00:11,  3.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 39/41 [02:17<00:07,  3.63s/it]#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 40/41 [02:20<00:03,  3.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 41/41 [02:24<00:00,  3.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5207687020301819, 'eval_rouge1': 44.6369, 'eval_rouge2': 26.7515, 'eval_rougeL': 31.6508, 'eval_rougeLsum': 31.7038, 'eval_gen_len': 80.878, 'eval_runtime': 148.6952, 'eval_samples_per_second': 0.551, 'eval_steps_per_second': 0.276, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m40%|████      | 654/1635 [09:53<06:48,  2.40it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 41/41 [02:25<00:00,  3.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-654\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-654\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-654/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-654/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-654/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-654/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-654/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-654/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-654/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-654/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\u001b[0m\n",
      "\u001b[34m40%|████      | 655/1635 [09:55<12:24:27, 45.58s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 656/1635 [09:56<8:42:45, 32.04s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 657/1635 [09:56<6:07:44, 22.56s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 658/1635 [09:56<4:19:19, 15.93s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 659/1635 [09:57<3:03:32, 11.28s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 660/1635 [09:57<2:10:27,  8.03s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 661/1635 [09:58<1:33:21,  5.75s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 662/1635 [09:58<1:07:26,  4.16s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 663/1635 [09:59<49:22,  3.05s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 664/1635 [09:59<36:40,  2.27s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 665/1635 [10:00<27:47,  1.72s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 666/1635 [10:00<21:37,  1.34s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 667/1635 [10:00<17:15,  1.07s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 668/1635 [10:01<14:10,  1.14it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 669/1635 [10:01<12:08,  1.33it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 670/1635 [10:02<10:36,  1.52it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 671/1635 [10:02<09:39,  1.66it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 672/1635 [10:03<08:56,  1.79it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 673/1635 [10:03<08:32,  1.88it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 674/1635 [10:04<08:11,  1.96it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 675/1635 [10:04<07:49,  2.05it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 676/1635 [10:05<07:36,  2.10it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 677/1635 [10:05<07:26,  2.15it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 678/1635 [10:05<07:18,  2.18it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 679/1635 [10:06<07:12,  2.21it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 680/1635 [10:06<07:12,  2.21it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 681/1635 [10:07<07:08,  2.23it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 682/1635 [10:07<07:06,  2.23it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 683/1635 [10:08<07:03,  2.25it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 684/1635 [10:08<07:04,  2.24it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 685/1635 [10:09<07:01,  2.26it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 686/1635 [10:09<06:58,  2.27it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 687/1635 [10:09<06:57,  2.27it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 688/1635 [10:10<06:55,  2.28it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 689/1635 [10:10<06:58,  2.26it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 690/1635 [10:11<06:59,  2.26it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 691/1635 [10:11<06:59,  2.25it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 692/1635 [10:12<07:01,  2.24it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 693/1635 [10:12<07:05,  2.22it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 694/1635 [10:13<07:07,  2.20it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 695/1635 [10:13<07:01,  2.23it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 696/1635 [10:13<07:02,  2.22it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 697/1635 [10:14<07:05,  2.21it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 698/1635 [10:14<07:02,  2.22it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 699/1635 [10:15<07:12,  2.16it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 700/1635 [10:15<07:07,  2.19it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 701/1635 [10:16<07:00,  2.22it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 702/1635 [10:16<06:57,  2.23it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 703/1635 [10:17<06:55,  2.24it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 704/1635 [10:17<07:04,  2.19it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 705/1635 [10:18<07:00,  2.21it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 706/1635 [10:18<07:03,  2.20it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 707/1635 [10:18<06:59,  2.21it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 708/1635 [10:19<06:54,  2.24it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 709/1635 [10:19<06:51,  2.25it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 710/1635 [10:20<06:50,  2.25it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 711/1635 [10:20<06:46,  2.27it/s]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 712/1635 [10:21<06:58,  2.21it/s]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 713/1635 [10:21<07:26,  2.06it/s]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 714/1635 [10:22<07:14,  2.12it/s]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 715/1635 [10:22<07:03,  2.17it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 716/1635 [10:23<06:57,  2.20it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 717/1635 [10:23<06:55,  2.21it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 718/1635 [10:23<06:51,  2.23it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 719/1635 [10:24<06:52,  2.22it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 720/1635 [10:24<06:51,  2.22it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 721/1635 [10:25<06:53,  2.21it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 722/1635 [10:25<06:51,  2.22it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 723/1635 [10:26<06:50,  2.22it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 724/1635 [10:26<06:48,  2.23it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 725/1635 [10:27<06:44,  2.25it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 726/1635 [10:27<06:40,  2.27it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 727/1635 [10:27<06:37,  2.28it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 728/1635 [10:28<06:39,  2.27it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 729/1635 [10:28<06:36,  2.28it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 730/1635 [10:29<06:34,  2.29it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 731/1635 [10:29<06:33,  2.30it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 732/1635 [10:30<06:37,  2.27it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 733/1635 [10:30<06:34,  2.29it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 734/1635 [10:30<06:39,  2.26it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 735/1635 [10:31<06:40,  2.25it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 736/1635 [10:31<06:39,  2.25it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 737/1635 [10:32<06:42,  2.23it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 738/1635 [10:32<06:37,  2.26it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 739/1635 [10:33<06:35,  2.26it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 740/1635 [10:33<06:35,  2.26it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 741/1635 [10:34<06:40,  2.23it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 742/1635 [10:34<06:36,  2.25it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 743/1635 [10:34<06:34,  2.26it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 744/1635 [10:35<06:38,  2.23it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 745/1635 [10:35<06:42,  2.21it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 746/1635 [10:36<06:42,  2.21it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 747/1635 [10:36<06:49,  2.17it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 748/1635 [10:37<06:46,  2.18it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 749/1635 [10:37<06:40,  2.21it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 750/1635 [10:38<06:49,  2.16it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 751/1635 [10:38<06:48,  2.17it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 752/1635 [10:39<06:52,  2.14it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 753/1635 [10:39<06:50,  2.15it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 754/1635 [10:40<06:53,  2.13it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 755/1635 [10:40<06:58,  2.10it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 756/1635 [10:41<06:52,  2.13it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 757/1635 [10:41<06:42,  2.18it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 758/1635 [10:41<06:37,  2.21it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 759/1635 [10:42<06:35,  2.22it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 760/1635 [10:42<06:35,  2.21it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 761/1635 [10:43<06:36,  2.20it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 762/1635 [10:43<06:32,  2.22it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 763/1635 [10:44<06:32,  2.22it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 764/1635 [10:44<06:41,  2.17it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 765/1635 [10:45<06:42,  2.16it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 766/1635 [10:45<06:36,  2.19it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 767/1635 [10:45<06:32,  2.21it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 768/1635 [10:46<06:26,  2.24it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 769/1635 [10:46<06:23,  2.26it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 770/1635 [10:47<06:22,  2.26it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 771/1635 [10:47<06:26,  2.23it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 772/1635 [10:48<06:23,  2.25it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 773/1635 [10:48<06:20,  2.27it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 774/1635 [10:49<06:19,  2.27it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 775/1635 [10:49<06:19,  2.26it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 776/1635 [10:49<06:24,  2.24it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 777/1635 [10:50<06:22,  2.24it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 778/1635 [10:50<06:19,  2.26it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 779/1635 [10:51<06:18,  2.26it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 780/1635 [10:51<06:15,  2.28it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 781/1635 [10:52<06:16,  2.27it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 782/1635 [10:52<06:13,  2.28it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 783/1635 [10:53<06:11,  2.29it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 784/1635 [10:53<06:14,  2.27it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 785/1635 [10:53<06:13,  2.27it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 786/1635 [10:54<06:14,  2.27it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 787/1635 [10:54<06:13,  2.27it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 788/1635 [10:55<06:19,  2.23it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 789/1635 [10:55<06:22,  2.21it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 790/1635 [10:56<06:39,  2.12it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 791/1635 [10:56<06:29,  2.17it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 792/1635 [10:57<06:22,  2.20it/s]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 793/1635 [10:57<06:15,  2.24it/s]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 794/1635 [10:58<06:20,  2.21it/s]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 795/1635 [10:58<06:20,  2.21it/s]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 796/1635 [10:58<06:14,  2.24it/s]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 797/1635 [10:59<06:13,  2.25it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 798/1635 [10:59<06:18,  2.21it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 799/1635 [11:00<06:17,  2.22it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 800/1635 [11:00<06:27,  2.16it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 801/1635 [11:01<06:35,  2.11it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 802/1635 [11:01<06:27,  2.15it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 803/1635 [11:02<06:19,  2.19it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 804/1635 [11:02<06:14,  2.22it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 805/1635 [11:03<06:09,  2.25it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 806/1635 [11:03<06:08,  2.25it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 807/1635 [11:03<06:06,  2.26it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 808/1635 [11:04<06:03,  2.28it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 809/1635 [11:04<06:05,  2.26it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 810/1635 [11:05<06:03,  2.27it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 811/1635 [11:05<06:02,  2.27it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 812/1635 [11:06<06:03,  2.26it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 813/1635 [11:06<06:02,  2.27it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 814/1635 [11:06<05:59,  2.28it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 815/1635 [11:07<05:57,  2.29it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 816/1635 [11:07<06:00,  2.27it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 817/1635 [11:08<06:01,  2.26it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 818/1635 [11:08<06:08,  2.22it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 819/1635 [11:09<06:06,  2.23it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 820/1635 [11:09<06:08,  2.21it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 821/1635 [11:10<06:11,  2.19it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 822/1635 [11:10<06:06,  2.22it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 823/1635 [11:11<06:03,  2.24it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 824/1635 [11:11<06:03,  2.23it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 825/1635 [11:11<05:59,  2.26it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 826/1635 [11:12<05:57,  2.26it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 827/1635 [11:12<05:55,  2.28it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 828/1635 [11:13<05:52,  2.29it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 829/1635 [11:13<05:51,  2.29it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 830/1635 [11:14<05:52,  2.28it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 831/1635 [11:14<05:51,  2.29it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 832/1635 [11:14<05:49,  2.30it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 833/1635 [11:15<05:53,  2.27it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 834/1635 [11:15<05:55,  2.25it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 835/1635 [11:16<05:53,  2.26it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 836/1635 [11:16<05:58,  2.23it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 837/1635 [11:17<05:54,  2.25it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 838/1635 [11:17<05:51,  2.27it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 839/1635 [11:18<05:56,  2.23it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 840/1635 [11:18<05:51,  2.26it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 841/1635 [11:18<05:47,  2.28it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 842/1635 [11:19<05:48,  2.27it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 843/1635 [11:19<05:50,  2.26it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 844/1635 [11:20<05:58,  2.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 845/1635 [11:20<05:57,  2.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 846/1635 [11:21<06:01,  2.18it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 847/1635 [11:21<06:04,  2.16it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 848/1635 [11:22<06:02,  2.17it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 849/1635 [11:22<05:59,  2.19it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 850/1635 [11:23<05:54,  2.22it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 851/1635 [11:23<05:50,  2.24it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 852/1635 [11:23<05:49,  2.24it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 853/1635 [11:24<05:52,  2.22it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 854/1635 [11:24<05:53,  2.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 855/1635 [11:25<05:51,  2.22it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 856/1635 [11:25<05:52,  2.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 857/1635 [11:26<05:48,  2.23it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 858/1635 [11:26<05:46,  2.24it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 859/1635 [11:27<05:42,  2.26it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 860/1635 [11:27<05:39,  2.28it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 861/1635 [11:27<05:42,  2.26it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 862/1635 [11:28<05:43,  2.25it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 863/1635 [11:28<05:41,  2.26it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 864/1635 [11:29<05:39,  2.27it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 865/1635 [11:29<05:37,  2.28it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 866/1635 [11:30<05:40,  2.26it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 867/1635 [11:30<05:56,  2.15it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 868/1635 [11:31<05:57,  2.14it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 869/1635 [11:31<05:50,  2.19it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 870/1635 [11:32<05:50,  2.19it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 871/1635 [11:32<05:47,  2.20it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 872/1635 [11:32<05:46,  2.20it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 873/1635 [11:33<05:44,  2.21it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 874/1635 [11:33<05:46,  2.19it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 875/1635 [11:34<05:51,  2.16it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 876/1635 [11:34<05:57,  2.12it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 877/1635 [11:35<05:55,  2.13it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 878/1635 [11:35<06:01,  2.09it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 879/1635 [11:36<05:58,  2.11it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 880/1635 [11:36<05:54,  2.13it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 881/1635 [11:37<05:52,  2.14it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 882/1635 [11:37<05:45,  2.18it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 883/1635 [11:38<05:57,  2.11it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 884/1635 [11:38<05:49,  2.15it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 885/1635 [11:39<05:57,  2.10it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 886/1635 [11:39<06:00,  2.08it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 887/1635 [11:40<06:07,  2.04it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 888/1635 [11:40<06:08,  2.03it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 889/1635 [11:41<06:03,  2.05it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 890/1635 [11:41<05:50,  2.13it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 891/1635 [11:41<05:48,  2.14it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 892/1635 [11:42<05:40,  2.18it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 893/1635 [11:42<05:34,  2.22it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 894/1635 [11:43<05:31,  2.24it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 895/1635 [11:43<05:27,  2.26it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 896/1635 [11:44<05:27,  2.25it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 897/1635 [11:44<05:27,  2.25it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 898/1635 [11:44<05:25,  2.27it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 899/1635 [11:45<05:22,  2.28it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 900/1635 [11:45<05:25,  2.26it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 901/1635 [11:46<05:26,  2.24it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 902/1635 [11:46<05:22,  2.27it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 903/1635 [11:47<05:25,  2.25it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 904/1635 [11:47<05:23,  2.26it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 905/1635 [11:48<05:24,  2.25it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 906/1635 [11:48<05:23,  2.25it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 907/1635 [11:48<05:23,  2.25it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 908/1635 [11:49<05:30,  2.20it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 909/1635 [11:49<05:28,  2.21it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 910/1635 [11:50<05:28,  2.21it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 911/1635 [11:50<05:24,  2.23it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 912/1635 [11:51<05:24,  2.23it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 913/1635 [11:51<05:24,  2.23it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 914/1635 [11:52<05:23,  2.23it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 915/1635 [11:52<05:30,  2.18it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 916/1635 [11:53<05:32,  2.16it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 917/1635 [11:53<05:27,  2.19it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 918/1635 [11:54<05:27,  2.19it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 919/1635 [11:54<05:22,  2.22it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 920/1635 [11:54<05:22,  2.21it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 921/1635 [11:55<05:23,  2.21it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 922/1635 [11:55<05:19,  2.23it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 923/1635 [11:56<05:15,  2.25it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 924/1635 [11:56<05:13,  2.27it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 925/1635 [11:57<05:13,  2.26it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 926/1635 [11:57<05:11,  2.28it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 927/1635 [11:57<05:07,  2.30it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 928/1635 [11:58<05:09,  2.29it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 929/1635 [11:58<05:09,  2.28it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 930/1635 [11:59<05:12,  2.26it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 931/1635 [11:59<05:12,  2.25it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 932/1635 [12:00<05:11,  2.26it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 933/1635 [12:00<05:07,  2.28it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 934/1635 [12:01<05:04,  2.30it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 935/1635 [12:01<05:04,  2.30it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 936/1635 [12:01<05:02,  2.31it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 937/1635 [12:02<05:02,  2.31it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 938/1635 [12:02<05:03,  2.30it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 939/1635 [12:03<05:02,  2.30it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 940/1635 [12:03<05:00,  2.31it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 941/1635 [12:04<04:59,  2.31it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 942/1635 [12:04<05:01,  2.30it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 943/1635 [12:04<04:59,  2.31it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 944/1635 [12:05<05:22,  2.14it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 945/1635 [12:05<05:14,  2.19it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 946/1635 [12:06<05:16,  2.18it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 947/1635 [12:06<05:14,  2.19it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 948/1635 [12:07<05:14,  2.18it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 949/1635 [12:07<05:11,  2.20it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 950/1635 [12:08<05:10,  2.21it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 951/1635 [12:08<05:12,  2.19it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 952/1635 [12:09<05:10,  2.20it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 953/1635 [12:09<05:09,  2.21it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 954/1635 [12:10<05:08,  2.21it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 955/1635 [12:10<05:12,  2.18it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 956/1635 [12:10<05:09,  2.19it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 957/1635 [12:11<05:08,  2.20it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 958/1635 [12:11<05:04,  2.22it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 959/1635 [12:12<05:00,  2.25it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 960/1635 [12:12<05:03,  2.22it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 961/1635 [12:13<05:01,  2.24it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 962/1635 [12:13<05:02,  2.22it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 963/1635 [12:14<05:05,  2.20it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 964/1635 [12:14<05:03,  2.21it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 965/1635 [12:14<05:01,  2.22it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 966/1635 [12:15<05:04,  2.20it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 967/1635 [12:15<04:58,  2.23it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 968/1635 [12:16<04:55,  2.26it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 969/1635 [12:16<05:02,  2.20it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 970/1635 [12:17<05:01,  2.21it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 971/1635 [12:17<05:00,  2.21it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 972/1635 [12:18<04:59,  2.21it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 973/1635 [12:18<04:55,  2.24it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 974/1635 [12:19<04:53,  2.25it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 975/1635 [12:19<04:51,  2.26it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 976/1635 [12:19<04:49,  2.28it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 977/1635 [12:20<04:51,  2.26it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 978/1635 [12:20<04:50,  2.26it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 979/1635 [12:21<04:47,  2.28it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 980/1635 [12:21<04:48,  2.27it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 981/1635 [12:22<04:35,  2.38it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4151, 'learning_rate': 1.1524229074889867e-05, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m60%|██████    | 981/1635 [12:22<04:35,  2.38it/s]\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 82\n",
      "  Batch size = 2\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 82\n",
      "  Batch size = 2\u001b[0m\n",
      "\u001b[34m0%|          | 0/41 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m5%|▍         | 2/41 [00:03<01:06,  1.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m7%|▋         | 3/41 [00:06<01:30,  2.38s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 4/41 [00:10<01:41,  2.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 5/41 [00:13<01:47,  2.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▍        | 6/41 [00:17<01:53,  3.25s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 7/41 [00:20<01:53,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m20%|█▉        | 8/41 [00:24<01:50,  3.36s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 9/41 [00:27<01:49,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m24%|██▍       | 10/41 [00:31<01:49,  3.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 11/41 [00:35<01:45,  3.51s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▉       | 12/41 [00:38<01:41,  3.51s/it]#033[A\u001b[0m\n",
      "\u001b[34m32%|███▏      | 13/41 [00:42<01:38,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m34%|███▍      | 14/41 [00:45<01:36,  3.56s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 15/41 [00:49<01:31,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 16/41 [00:52<01:27,  3.49s/it]#033[A\u001b[0m\n",
      "\u001b[34m41%|████▏     | 17/41 [00:56<01:24,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 18/41 [00:59<01:19,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▋     | 19/41 [01:02<01:15,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m49%|████▉     | 20/41 [01:06<01:12,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m51%|█████     | 21/41 [01:09<01:09,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 22/41 [01:13<01:06,  3.49s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 23/41 [01:17<01:03,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 24/41 [01:20<00:59,  3.48s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 25/41 [01:23<00:55,  3.48s/it]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 26/41 [01:27<00:52,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 27/41 [01:30<00:48,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 28/41 [01:34<00:44,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 29/41 [01:37<00:41,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 30/41 [01:40<00:37,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 31/41 [01:44<00:34,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 32/41 [01:47<00:31,  3.46s/it]#033[A\u001b[0m\n",
      "\u001b[34m80%|████████  | 33/41 [01:51<00:27,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 34/41 [01:54<00:23,  3.42s/it]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 35/41 [01:58<00:20,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 36/41 [02:01<00:17,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m90%|█████████ | 37/41 [02:05<00:13,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 38/41 [02:08<00:10,  3.46s/it]#033[A\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 39/41 [02:12<00:06,  3.48s/it]#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 40/41 [02:15<00:03,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 41/41 [02:19<00:00,  3.49s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.48328912258148193, 'eval_rouge1': 47.2031, 'eval_rouge2': 29.7004, 'eval_rougeL': 33.7416, 'eval_rougeLsum': 33.7854, 'eval_gen_len': 80.6585, 'eval_runtime': 143.6899, 'eval_samples_per_second': 0.571, 'eval_steps_per_second': 0.285, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m60%|██████    | 981/1635 [14:45<04:35,  2.38it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 41/41 [02:20<00:00,  3.49s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-981\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-981\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-981/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-981/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-981/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-981/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-981/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-981/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-981/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-981/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\u001b[0m\n",
      "\u001b[34m60%|██████    | 982/1635 [14:47<7:59:31, 44.06s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 983/1635 [14:48<5:36:33, 30.97s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 984/1635 [14:48<3:56:41, 21.81s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 985/1635 [14:49<2:47:09, 15.43s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 986/1635 [14:49<1:58:16, 10.94s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 987/1635 [14:50<1:24:05,  7.79s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 988/1635 [14:50<1:00:11,  5.58s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 989/1635 [14:51<43:35,  4.05s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 990/1635 [14:51<31:56,  2.97s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 991/1635 [14:52<23:44,  2.21s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 992/1635 [14:52<18:02,  1.68s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 993/1635 [14:52<13:59,  1.31s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 994/1635 [14:53<11:10,  1.05s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 995/1635 [14:53<09:12,  1.16it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 996/1635 [14:54<07:51,  1.36it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 997/1635 [14:54<07:01,  1.51it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 998/1635 [14:55<06:22,  1.67it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 999/1635 [14:55<05:53,  1.80it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1000/1635 [14:56<05:30,  1.92it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1001/1635 [14:56<05:16,  2.01it/s]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 1002/1635 [14:56<05:05,  2.07it/s]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 1003/1635 [14:57<05:00,  2.10it/s]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 1004/1635 [14:57<04:54,  2.15it/s]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 1005/1635 [14:58<04:48,  2.18it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1006/1635 [14:58<04:46,  2.19it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1007/1635 [14:59<04:50,  2.16it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1008/1635 [14:59<04:46,  2.19it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1009/1635 [15:00<04:45,  2.19it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1010/1635 [15:00<04:43,  2.20it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1011/1635 [15:01<04:44,  2.19it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1012/1635 [15:01<04:41,  2.21it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1013/1635 [15:01<04:37,  2.24it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1014/1635 [15:02<04:35,  2.25it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1015/1635 [15:02<04:35,  2.25it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1016/1635 [15:03<04:37,  2.23it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1017/1635 [15:03<04:39,  2.21it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1018/1635 [15:04<04:37,  2.22it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1019/1635 [15:04<04:35,  2.24it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1020/1635 [15:05<04:32,  2.26it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1021/1635 [15:05<04:32,  2.25it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1022/1635 [15:05<04:31,  2.26it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1023/1635 [15:06<04:33,  2.24it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1024/1635 [15:06<04:30,  2.26it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1025/1635 [15:07<04:28,  2.27it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1026/1635 [15:07<04:27,  2.27it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1027/1635 [15:08<04:29,  2.26it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1028/1635 [15:08<04:36,  2.20it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1029/1635 [15:09<04:34,  2.21it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1030/1635 [15:09<04:39,  2.17it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1031/1635 [15:09<04:36,  2.18it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1032/1635 [15:10<04:38,  2.17it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1033/1635 [15:10<04:35,  2.18it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1034/1635 [15:11<04:37,  2.16it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1035/1635 [15:11<04:35,  2.18it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1036/1635 [15:12<04:34,  2.18it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1037/1635 [15:12<04:37,  2.15it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1038/1635 [15:13<04:31,  2.20it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 1039/1635 [15:13<04:29,  2.21it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 1040/1635 [15:14<04:26,  2.23it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 1041/1635 [15:14<04:28,  2.21it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 1042/1635 [15:14<04:26,  2.22it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1043/1635 [15:15<04:28,  2.20it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1044/1635 [15:15<04:26,  2.22it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1045/1635 [15:16<04:26,  2.22it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1046/1635 [15:16<04:26,  2.21it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1047/1635 [15:17<04:23,  2.23it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1048/1635 [15:17<04:21,  2.25it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1049/1635 [15:18<04:21,  2.24it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1050/1635 [15:18<04:20,  2.25it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1051/1635 [15:18<04:18,  2.26it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1052/1635 [15:19<04:19,  2.25it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1053/1635 [15:19<04:16,  2.26it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1054/1635 [15:20<04:15,  2.28it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1055/1635 [15:20<04:22,  2.21it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1056/1635 [15:21<04:26,  2.17it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1057/1635 [15:21<04:23,  2.19it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1058/1635 [15:22<04:21,  2.21it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1059/1635 [15:22<04:19,  2.22it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1060/1635 [15:23<04:16,  2.24it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1061/1635 [15:23<04:13,  2.26it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1062/1635 [15:24<04:29,  2.13it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1063/1635 [15:24<04:22,  2.18it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1064/1635 [15:24<04:20,  2.19it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1065/1635 [15:25<04:16,  2.22it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1066/1635 [15:25<04:12,  2.25it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1067/1635 [15:26<04:11,  2.26it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1068/1635 [15:26<04:12,  2.25it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1069/1635 [15:27<04:11,  2.25it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1070/1635 [15:27<04:09,  2.27it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1071/1635 [15:27<04:09,  2.26it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1072/1635 [15:28<04:09,  2.26it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1073/1635 [15:28<04:09,  2.25it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1074/1635 [15:29<04:15,  2.20it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1075/1635 [15:29<04:14,  2.20it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1076/1635 [15:30<04:13,  2.20it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1077/1635 [15:30<04:09,  2.24it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1078/1635 [15:31<04:06,  2.26it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1079/1635 [15:31<04:07,  2.25it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1080/1635 [15:32<04:06,  2.25it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1081/1635 [15:32<04:04,  2.26it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1082/1635 [15:32<04:06,  2.25it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1083/1635 [15:33<04:05,  2.25it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 1084/1635 [15:33<04:06,  2.24it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 1085/1635 [15:34<04:06,  2.23it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 1086/1635 [15:34<04:05,  2.23it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 1087/1635 [15:35<04:08,  2.21it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1088/1635 [15:35<04:08,  2.20it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1089/1635 [15:36<04:11,  2.17it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1090/1635 [15:36<04:11,  2.16it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1091/1635 [15:36<04:09,  2.18it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1092/1635 [15:37<04:10,  2.17it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1093/1635 [15:37<04:12,  2.15it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1094/1635 [15:38<04:09,  2.17it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1095/1635 [15:38<04:12,  2.13it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1096/1635 [15:39<04:18,  2.09it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1097/1635 [15:39<04:23,  2.04it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1098/1635 [15:40<04:26,  2.02it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1099/1635 [15:40<04:29,  1.99it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1100/1635 [15:41<04:21,  2.04it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1101/1635 [15:41<04:15,  2.09it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1102/1635 [15:42<04:10,  2.13it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1103/1635 [15:42<04:07,  2.15it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1104/1635 [15:43<04:06,  2.15it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1105/1635 [15:43<04:03,  2.18it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1106/1635 [15:44<04:04,  2.17it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1107/1635 [15:44<04:07,  2.14it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1108/1635 [15:45<04:05,  2.15it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1109/1635 [15:45<04:01,  2.17it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1110/1635 [15:45<03:59,  2.19it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1111/1635 [15:46<03:59,  2.19it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1112/1635 [15:46<03:57,  2.20it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1113/1635 [15:47<03:56,  2.21it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1114/1635 [15:47<03:54,  2.22it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1115/1635 [15:48<03:52,  2.24it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1116/1635 [15:48<03:50,  2.25it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1117/1635 [15:49<03:50,  2.25it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1118/1635 [15:49<03:52,  2.22it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1119/1635 [15:49<03:51,  2.23it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 1120/1635 [15:50<03:57,  2.17it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 1121/1635 [15:50<03:55,  2.18it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 1122/1635 [15:51<03:57,  2.16it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 1123/1635 [15:51<03:57,  2.15it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 1124/1635 [15:52<03:53,  2.19it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1125/1635 [15:52<03:48,  2.23it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1126/1635 [15:53<03:45,  2.26it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1127/1635 [15:53<03:50,  2.20it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1128/1635 [15:54<03:47,  2.23it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1129/1635 [15:54<03:44,  2.25it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1130/1635 [15:54<03:43,  2.26it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1131/1635 [15:55<03:46,  2.23it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1132/1635 [15:55<03:45,  2.23it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1133/1635 [15:56<03:45,  2.23it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1134/1635 [15:56<03:47,  2.20it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1135/1635 [15:57<03:45,  2.22it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1136/1635 [15:57<03:43,  2.23it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1137/1635 [15:58<03:49,  2.17it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1138/1635 [15:58<03:48,  2.17it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1139/1635 [15:59<04:00,  2.06it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1140/1635 [15:59<03:56,  2.09it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1141/1635 [16:00<03:51,  2.13it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1142/1635 [16:00<03:53,  2.12it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1143/1635 [16:01<03:50,  2.13it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1144/1635 [16:01<03:48,  2.14it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1145/1635 [16:01<03:46,  2.17it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1146/1635 [16:02<03:47,  2.15it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1147/1635 [16:02<03:43,  2.18it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1148/1635 [16:03<03:43,  2.18it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1149/1635 [16:03<03:41,  2.19it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1150/1635 [16:04<03:41,  2.19it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1151/1635 [16:04<03:40,  2.19it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1152/1635 [16:05<03:42,  2.17it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1153/1635 [16:05<03:39,  2.20it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1154/1635 [16:06<03:36,  2.22it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1155/1635 [16:06<03:34,  2.24it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1156/1635 [16:06<03:33,  2.25it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1157/1635 [16:07<03:31,  2.26it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1158/1635 [16:07<03:31,  2.26it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1159/1635 [16:08<03:37,  2.18it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1160/1635 [16:08<03:35,  2.20it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1161/1635 [16:09<03:33,  2.22it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1162/1635 [16:09<03:32,  2.22it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1163/1635 [16:10<03:30,  2.24it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1164/1635 [16:10<03:33,  2.21it/s]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 1165/1635 [16:10<03:32,  2.21it/s]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 1166/1635 [16:11<03:30,  2.22it/s]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 1167/1635 [16:11<03:29,  2.24it/s]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 1168/1635 [16:12<03:31,  2.21it/s]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 1169/1635 [16:12<03:28,  2.23it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1170/1635 [16:13<03:27,  2.24it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1171/1635 [16:13<03:26,  2.25it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1172/1635 [16:14<03:26,  2.24it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1173/1635 [16:14<03:25,  2.24it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1174/1635 [16:14<03:26,  2.23it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1175/1635 [16:15<03:25,  2.24it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1176/1635 [16:15<03:23,  2.25it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1177/1635 [16:16<03:21,  2.28it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1178/1635 [16:16<03:19,  2.29it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1179/1635 [16:17<03:20,  2.27it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1180/1635 [16:17<03:19,  2.28it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1181/1635 [16:18<03:19,  2.28it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1182/1635 [16:18<03:18,  2.28it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1183/1635 [16:18<03:20,  2.25it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1184/1635 [16:19<03:21,  2.23it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1185/1635 [16:19<03:19,  2.25it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1186/1635 [16:20<03:19,  2.25it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1187/1635 [16:20<03:18,  2.26it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1188/1635 [16:21<03:16,  2.27it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1189/1635 [16:21<03:15,  2.28it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1190/1635 [16:22<03:16,  2.27it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1191/1635 [16:22<03:16,  2.26it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1192/1635 [16:22<03:20,  2.20it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1193/1635 [16:23<03:20,  2.21it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1194/1635 [16:23<03:24,  2.16it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1195/1635 [16:24<03:20,  2.19it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1196/1635 [16:24<03:17,  2.22it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1197/1635 [16:25<03:16,  2.23it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1198/1635 [16:25<03:16,  2.22it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1199/1635 [16:26<03:16,  2.22it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1200/1635 [16:26<03:14,  2.24it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1201/1635 [16:27<03:18,  2.19it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 1202/1635 [16:27<03:22,  2.14it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 1203/1635 [16:27<03:18,  2.18it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 1204/1635 [16:28<03:14,  2.21it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 1205/1635 [16:28<03:12,  2.24it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1206/1635 [16:29<03:10,  2.25it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1207/1635 [16:29<03:10,  2.25it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1208/1635 [16:30<03:09,  2.25it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1209/1635 [16:30<03:08,  2.26it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1210/1635 [16:31<03:06,  2.28it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1211/1635 [16:31<03:07,  2.26it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1212/1635 [16:31<03:06,  2.27it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1213/1635 [16:32<03:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1214/1635 [16:32<03:09,  2.22it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1215/1635 [16:33<03:14,  2.16it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1216/1635 [16:33<03:25,  2.04it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1217/1635 [16:34<03:18,  2.10it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1218/1635 [16:34<03:16,  2.13it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1219/1635 [16:35<03:11,  2.17it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1220/1635 [16:35<03:11,  2.17it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1221/1635 [16:36<03:11,  2.16it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1222/1635 [16:36<03:09,  2.18it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1223/1635 [16:37<03:08,  2.19it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1224/1635 [16:37<03:07,  2.19it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1225/1635 [16:37<03:06,  2.20it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1226/1635 [16:38<03:06,  2.20it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1227/1635 [16:38<03:05,  2.20it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1228/1635 [16:39<03:09,  2.15it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1229/1635 [16:39<03:07,  2.16it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1230/1635 [16:40<03:07,  2.16it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1231/1635 [16:40<03:13,  2.09it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1232/1635 [16:41<03:17,  2.04it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1233/1635 [16:41<03:11,  2.10it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1234/1635 [16:42<03:07,  2.14it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1235/1635 [16:42<03:02,  2.19it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1236/1635 [16:43<03:01,  2.20it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1237/1635 [16:43<02:58,  2.23it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1238/1635 [16:43<02:56,  2.25it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1239/1635 [16:44<02:56,  2.25it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1240/1635 [16:44<02:55,  2.25it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1241/1635 [16:45<02:54,  2.26it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1242/1635 [16:45<02:53,  2.27it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1243/1635 [16:46<02:54,  2.25it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1244/1635 [16:46<02:54,  2.24it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1245/1635 [16:47<02:55,  2.22it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1246/1635 [16:47<02:57,  2.19it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 1247/1635 [16:47<02:55,  2.21it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 1248/1635 [16:48<02:56,  2.19it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 1249/1635 [16:48<02:56,  2.19it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 1250/1635 [16:49<02:55,  2.19it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1251/1635 [16:49<02:53,  2.21it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1252/1635 [16:50<02:52,  2.21it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1253/1635 [16:50<02:50,  2.23it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1254/1635 [16:51<02:50,  2.24it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1255/1635 [16:51<02:48,  2.25it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1256/1635 [16:52<02:48,  2.24it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1257/1635 [16:52<02:49,  2.24it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1258/1635 [16:52<02:50,  2.21it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1259/1635 [16:53<02:51,  2.20it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1260/1635 [16:53<02:51,  2.18it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1261/1635 [16:54<02:48,  2.22it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1262/1635 [16:54<02:51,  2.18it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1263/1635 [16:55<02:49,  2.20it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1264/1635 [16:55<02:48,  2.20it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1265/1635 [16:56<02:49,  2.19it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1266/1635 [16:56<02:48,  2.19it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1267/1635 [16:57<02:45,  2.22it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1268/1635 [16:57<02:45,  2.21it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1269/1635 [16:57<02:44,  2.23it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1270/1635 [16:58<02:46,  2.20it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1271/1635 [16:58<02:45,  2.20it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1272/1635 [16:59<02:44,  2.21it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1273/1635 [16:59<02:43,  2.22it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1274/1635 [17:00<02:44,  2.20it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1275/1635 [17:00<02:42,  2.22it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1276/1635 [17:01<02:42,  2.21it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1277/1635 [17:01<02:42,  2.21it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1278/1635 [17:02<02:41,  2.21it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1279/1635 [17:02<02:40,  2.22it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1280/1635 [17:02<02:39,  2.23it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1281/1635 [17:03<02:41,  2.20it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1282/1635 [17:03<02:39,  2.22it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1283/1635 [17:04<02:39,  2.21it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 1284/1635 [17:04<02:38,  2.21it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 1285/1635 [17:05<02:37,  2.22it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 1286/1635 [17:05<02:36,  2.22it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 1287/1635 [17:06<02:34,  2.25it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1288/1635 [17:06<02:34,  2.25it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1289/1635 [17:06<02:33,  2.25it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1290/1635 [17:07<02:32,  2.26it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1291/1635 [17:07<02:34,  2.22it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1292/1635 [17:08<02:34,  2.21it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1293/1635 [17:08<02:42,  2.11it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1294/1635 [17:09<02:38,  2.16it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1295/1635 [17:09<02:35,  2.19it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1296/1635 [17:10<02:34,  2.19it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1297/1635 [17:10<02:33,  2.21it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1298/1635 [17:11<02:31,  2.22it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1299/1635 [17:11<02:34,  2.18it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1300/1635 [17:11<02:33,  2.18it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1301/1635 [17:12<02:34,  2.16it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1302/1635 [17:12<02:32,  2.18it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1303/1635 [17:13<02:29,  2.22it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1304/1635 [17:13<02:27,  2.24it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1305/1635 [17:14<02:27,  2.23it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1306/1635 [17:14<02:26,  2.25it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1307/1635 [17:15<02:26,  2.25it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1308/1635 [17:15<02:19,  2.34it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3246, 'learning_rate': 5.762114537444934e-06, 'epoch': 4.0}\u001b[0m\n",
      "\u001b[34m80%|████████  | 1308/1635 [17:15<02:19,  2.34it/s]\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 82\u001b[0m\n",
      "\u001b[34mBatch size = 2\u001b[0m\n",
      "\u001b[34mNum examples = 82\n",
      "  Batch size = 2\u001b[0m\n",
      "\u001b[34m0%|          | 0/41 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m5%|▍         | 2/41 [00:03<01:08,  1.77s/it]#033[A\u001b[0m\n",
      "\u001b[34m7%|▋         | 3/41 [00:07<01:36,  2.53s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 4/41 [00:10<01:47,  2.90s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 5/41 [00:14<01:52,  3.14s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▍        | 6/41 [00:17<01:54,  3.26s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 7/41 [00:21<01:55,  3.38s/it]#033[A\u001b[0m\n",
      "\u001b[34m20%|█▉        | 8/41 [00:25<01:54,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 9/41 [00:28<01:50,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m24%|██▍       | 10/41 [00:31<01:46,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 11/41 [00:35<01:43,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▉       | 12/41 [00:38<01:40,  3.46s/it]#033[A\u001b[0m\n",
      "\u001b[34m32%|███▏      | 13/41 [00:42<01:36,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m34%|███▍      | 14/41 [00:45<01:33,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 15/41 [00:49<01:28,  3.42s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 16/41 [00:52<01:25,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m41%|████▏     | 17/41 [00:56<01:22,  3.46s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 18/41 [00:59<01:18,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▋     | 19/41 [01:02<01:15,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m49%|████▉     | 20/41 [01:06<01:11,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m51%|█████     | 21/41 [01:09<01:08,  3.41s/it]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 22/41 [01:12<01:04,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 23/41 [01:16<01:01,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 24/41 [01:19<00:57,  3.40s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 25/41 [01:23<00:56,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 26/41 [01:27<00:53,  3.53s/it]#033[A\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 27/41 [01:30<00:49,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 28/41 [01:34<00:45,  3.53s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 29/41 [01:37<00:43,  3.59s/it]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 30/41 [01:41<00:39,  3.59s/it]#033[A\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 31/41 [01:45<00:36,  3.62s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 32/41 [01:48<00:32,  3.59s/it]#033[A\u001b[0m\n",
      "\u001b[34m80%|████████  | 33/41 [01:51<00:28,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 34/41 [01:55<00:24,  3.46s/it]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 35/41 [01:58<00:20,  3.48s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 36/41 [02:02<00:17,  3.50s/it]#033[A\u001b[0m\n",
      "\u001b[34m90%|█████████ | 37/41 [02:05<00:14,  3.51s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 38/41 [02:09<00:10,  3.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 39/41 [02:12<00:06,  3.49s/it]#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 40/41 [02:16<00:03,  3.49s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 41/41 [02:19<00:00,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.45152392983436584, 'eval_rouge1': 46.434, 'eval_rouge2': 29.5802, 'eval_rougeL': 33.7212, 'eval_rougeLsum': 33.7369, 'eval_gen_len': 80.4634, 'eval_runtime': 144.5937, 'eval_samples_per_second': 0.567, 'eval_steps_per_second': 0.284, 'epoch': 4.0}\u001b[0m\n",
      "\u001b[34m80%|████████  | 1308/1635 [19:40<02:19,  2.34it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 41/41 [02:21<00:00,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-1308\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-1308\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-1308/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-1308/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-1308/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-1308/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-1308/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-1308/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-1308/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-1308/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mDeleting older checkpoint [/opt/ml/model/checkpoint-327] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34mDeleting older checkpoint [/opt/ml/model/checkpoint-327] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\u001b[0m\n",
      "\u001b[34m80%|████████  | 1309/1635 [19:42<4:01:17, 44.41s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1310/1635 [19:42<2:49:07, 31.22s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1311/1635 [19:43<1:58:44, 21.99s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1312/1635 [19:43<1:23:34, 15.52s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1313/1635 [19:44<59:02, 11.00s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1314/1635 [19:44<41:53,  7.83s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1315/1635 [19:45<29:56,  5.61s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1316/1635 [19:45<21:37,  4.07s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1317/1635 [19:46<15:47,  2.98s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1318/1635 [19:46<11:43,  2.22s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1319/1635 [19:46<08:53,  1.69s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1320/1635 [19:47<06:53,  1.31s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1321/1635 [19:47<05:39,  1.08s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1322/1635 [19:48<04:38,  1.12it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1323/1635 [19:48<03:55,  1.33it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1324/1635 [19:49<03:28,  1.49it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1325/1635 [19:49<03:09,  1.64it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1326/1635 [19:50<02:53,  1.78it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1327/1635 [19:50<02:42,  1.90it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1328/1635 [19:51<02:34,  1.98it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 1329/1635 [19:51<02:28,  2.07it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 1330/1635 [19:52<02:23,  2.13it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 1331/1635 [19:52<02:19,  2.18it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 1332/1635 [19:52<02:17,  2.21it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1333/1635 [19:53<02:15,  2.23it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1334/1635 [19:53<02:14,  2.24it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1335/1635 [19:54<02:13,  2.25it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1336/1635 [19:54<02:15,  2.20it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1337/1635 [19:55<02:16,  2.19it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1338/1635 [19:55<02:18,  2.15it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1339/1635 [19:56<02:17,  2.15it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1340/1635 [19:56<02:16,  2.17it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1341/1635 [19:57<02:15,  2.18it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1342/1635 [19:57<02:12,  2.20it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1343/1635 [19:57<02:11,  2.22it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1344/1635 [19:58<02:12,  2.19it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1345/1635 [19:58<02:11,  2.20it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1346/1635 [19:59<02:10,  2.22it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1347/1635 [19:59<02:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1348/1635 [20:00<02:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1349/1635 [20:00<02:07,  2.25it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1350/1635 [20:01<02:07,  2.24it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1351/1635 [20:01<02:06,  2.25it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1352/1635 [20:01<02:06,  2.24it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1353/1635 [20:02<02:06,  2.23it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1354/1635 [20:02<02:04,  2.25it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1355/1635 [20:03<02:03,  2.27it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1356/1635 [20:03<02:02,  2.28it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1357/1635 [20:04<02:02,  2.27it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1358/1635 [20:04<02:04,  2.22it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1359/1635 [20:05<02:04,  2.21it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1360/1635 [20:05<02:03,  2.23it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1361/1635 [20:05<02:03,  2.22it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1362/1635 [20:06<02:01,  2.24it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1363/1635 [20:06<02:03,  2.20it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1364/1635 [20:07<02:02,  2.21it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1365/1635 [20:07<02:00,  2.24it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 1366/1635 [20:08<02:00,  2.24it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 1367/1635 [20:08<01:58,  2.25it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 1368/1635 [20:09<01:59,  2.24it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 1369/1635 [20:09<02:00,  2.20it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1370/1635 [20:09<01:59,  2.22it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1371/1635 [20:10<01:58,  2.23it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1372/1635 [20:10<01:56,  2.26it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1373/1635 [20:11<01:55,  2.28it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1374/1635 [20:11<01:53,  2.29it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1375/1635 [20:12<01:54,  2.27it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1376/1635 [20:12<01:53,  2.28it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1377/1635 [20:13<01:53,  2.28it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1378/1635 [20:13<01:53,  2.27it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1379/1635 [20:13<01:52,  2.28it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1380/1635 [20:14<01:51,  2.29it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1381/1635 [20:14<01:51,  2.28it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1382/1635 [20:15<01:51,  2.28it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1383/1635 [20:15<01:50,  2.28it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1384/1635 [20:16<01:50,  2.27it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1385/1635 [20:16<01:50,  2.27it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1386/1635 [20:16<01:49,  2.27it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1387/1635 [20:17<01:49,  2.26it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1388/1635 [20:17<01:49,  2.25it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1389/1635 [20:18<01:50,  2.23it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1390/1635 [20:18<01:52,  2.17it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1391/1635 [20:19<01:52,  2.17it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1392/1635 [20:19<01:54,  2.12it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1393/1635 [20:20<01:55,  2.10it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1394/1635 [20:20<01:52,  2.14it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1395/1635 [20:21<01:52,  2.13it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1396/1635 [20:21<01:50,  2.17it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1397/1635 [20:22<01:48,  2.19it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1398/1635 [20:22<01:54,  2.07it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1399/1635 [20:23<01:52,  2.11it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1400/1635 [20:23<01:49,  2.15it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1401/1635 [20:23<01:46,  2.19it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1402/1635 [20:24<01:45,  2.21it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1403/1635 [20:24<01:44,  2.22it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1404/1635 [20:25<01:43,  2.23it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1405/1635 [20:25<01:43,  2.22it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1406/1635 [20:26<01:43,  2.22it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1407/1635 [20:26<01:41,  2.24it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1408/1635 [20:27<01:40,  2.26it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1409/1635 [20:27<01:40,  2.25it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1410/1635 [20:27<01:39,  2.26it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1411/1635 [20:28<01:38,  2.28it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1412/1635 [20:28<01:39,  2.25it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1413/1635 [20:29<01:38,  2.25it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1414/1635 [20:29<01:38,  2.25it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1415/1635 [20:30<01:38,  2.24it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1416/1635 [20:30<01:36,  2.27it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1417/1635 [20:31<01:37,  2.24it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1418/1635 [20:31<01:36,  2.25it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1419/1635 [20:31<01:35,  2.26it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1420/1635 [20:32<01:34,  2.27it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1421/1635 [20:32<01:34,  2.26it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1422/1635 [20:33<01:34,  2.25it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1423/1635 [20:33<01:33,  2.27it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1424/1635 [20:34<01:32,  2.28it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1425/1635 [20:34<01:32,  2.28it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1426/1635 [20:35<01:31,  2.28it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1427/1635 [20:35<01:32,  2.25it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1428/1635 [20:35<01:31,  2.26it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1429/1635 [20:36<01:30,  2.28it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1430/1635 [20:36<01:29,  2.29it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1431/1635 [20:37<01:28,  2.30it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1432/1635 [20:37<01:29,  2.27it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1433/1635 [20:38<01:28,  2.27it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1434/1635 [20:38<01:28,  2.27it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1435/1635 [20:39<01:28,  2.25it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1436/1635 [20:39<01:30,  2.19it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1437/1635 [20:39<01:30,  2.19it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1438/1635 [20:40<01:29,  2.19it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1439/1635 [20:40<01:33,  2.09it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1440/1635 [20:41<01:34,  2.06it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1441/1635 [20:41<01:31,  2.11it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1442/1635 [20:42<01:29,  2.16it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1443/1635 [20:42<01:27,  2.20it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1444/1635 [20:43<01:25,  2.24it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1445/1635 [20:43<01:25,  2.23it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1446/1635 [20:44<01:25,  2.22it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1447/1635 [20:44<01:24,  2.24it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1448/1635 [20:44<01:23,  2.23it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1449/1635 [20:45<01:23,  2.24it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1450/1635 [20:45<01:22,  2.24it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1451/1635 [20:46<01:21,  2.26it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1452/1635 [20:46<01:20,  2.28it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1453/1635 [20:47<01:19,  2.29it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1454/1635 [20:47<01:19,  2.27it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1455/1635 [20:48<01:19,  2.28it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1456/1635 [20:48<01:18,  2.27it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1457/1635 [20:48<01:20,  2.21it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1458/1635 [20:49<01:20,  2.21it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1459/1635 [20:49<01:18,  2.24it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1460/1635 [20:50<01:17,  2.26it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1461/1635 [20:50<01:16,  2.27it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1462/1635 [20:51<01:15,  2.28it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1463/1635 [20:51<01:15,  2.28it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1464/1635 [20:52<01:14,  2.29it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1465/1635 [20:52<01:15,  2.27it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1466/1635 [20:52<01:14,  2.28it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1467/1635 [20:53<01:14,  2.27it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1468/1635 [20:53<01:13,  2.27it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1469/1635 [20:54<01:13,  2.26it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1470/1635 [20:54<01:13,  2.24it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1471/1635 [20:55<01:14,  2.21it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1472/1635 [20:55<01:14,  2.17it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1473/1635 [20:56<01:13,  2.19it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1474/1635 [20:56<01:12,  2.21it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1475/1635 [20:57<01:15,  2.12it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1476/1635 [20:57<01:14,  2.14it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1477/1635 [20:57<01:13,  2.16it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1478/1635 [20:58<01:12,  2.17it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1479/1635 [20:58<01:11,  2.17it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1480/1635 [20:59<01:09,  2.22it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1481/1635 [20:59<01:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1482/1635 [21:00<01:07,  2.25it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1483/1635 [21:00<01:07,  2.24it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1484/1635 [21:01<01:07,  2.25it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1485/1635 [21:01<01:07,  2.23it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1486/1635 [21:01<01:07,  2.22it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1487/1635 [21:02<01:05,  2.24it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1488/1635 [21:02<01:05,  2.26it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1489/1635 [21:03<01:04,  2.27it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1490/1635 [21:03<01:04,  2.26it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1491/1635 [21:04<01:03,  2.26it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1492/1635 [21:04<01:03,  2.25it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1493/1635 [21:05<01:03,  2.25it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1494/1635 [21:05<01:02,  2.26it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1495/1635 [21:05<01:02,  2.25it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1496/1635 [21:06<01:03,  2.18it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1497/1635 [21:06<01:02,  2.19it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1498/1635 [21:07<01:01,  2.22it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1499/1635 [21:07<01:00,  2.24it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1500/1635 [21:08<01:00,  2.23it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1501/1635 [21:08<00:59,  2.24it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1502/1635 [21:09<00:59,  2.23it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1503/1635 [21:09<00:58,  2.24it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1504/1635 [21:10<00:57,  2.26it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1505/1635 [21:10<00:57,  2.27it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1506/1635 [21:10<00:56,  2.26it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1507/1635 [21:11<00:56,  2.25it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1508/1635 [21:11<00:56,  2.25it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1509/1635 [21:12<00:56,  2.25it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1510/1635 [21:12<00:55,  2.25it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1511/1635 [21:13<00:55,  2.25it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1512/1635 [21:13<00:55,  2.23it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1513/1635 [21:14<00:54,  2.23it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1514/1635 [21:14<00:53,  2.25it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1515/1635 [21:14<00:53,  2.25it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1516/1635 [21:15<00:52,  2.26it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1517/1635 [21:15<00:52,  2.25it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1518/1635 [21:16<00:52,  2.24it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1519/1635 [21:16<00:52,  2.22it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1520/1635 [21:17<00:52,  2.20it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1521/1635 [21:17<00:51,  2.23it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1522/1635 [21:18<00:50,  2.25it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1523/1635 [21:18<00:49,  2.25it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1524/1635 [21:18<00:49,  2.26it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1525/1635 [21:19<00:48,  2.27it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1526/1635 [21:19<00:48,  2.25it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1527/1635 [21:20<00:48,  2.22it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1528/1635 [21:20<00:47,  2.24it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1529/1635 [21:21<00:46,  2.26it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1530/1635 [21:21<00:46,  2.28it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1531/1635 [21:22<00:45,  2.26it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1532/1635 [21:22<00:45,  2.25it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1533/1635 [21:22<00:45,  2.24it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1534/1635 [21:23<00:45,  2.24it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1535/1635 [21:23<00:44,  2.26it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1536/1635 [21:24<00:43,  2.27it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1537/1635 [21:24<00:43,  2.23it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1538/1635 [21:25<00:43,  2.21it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1539/1635 [21:25<00:43,  2.23it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1540/1635 [21:26<00:42,  2.24it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1541/1635 [21:26<00:42,  2.24it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1542/1635 [21:26<00:41,  2.23it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1543/1635 [21:27<00:41,  2.23it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1544/1635 [21:27<00:40,  2.23it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1545/1635 [21:28<00:39,  2.25it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1546/1635 [21:28<00:39,  2.25it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1547/1635 [21:29<00:39,  2.25it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1548/1635 [21:29<00:38,  2.26it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1549/1635 [21:30<00:38,  2.26it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1550/1635 [21:30<00:37,  2.26it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1551/1635 [21:30<00:37,  2.26it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1552/1635 [21:31<00:38,  2.13it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1553/1635 [21:31<00:37,  2.18it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1554/1635 [21:32<00:37,  2.18it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1555/1635 [21:32<00:36,  2.16it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1556/1635 [21:33<00:36,  2.15it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1557/1635 [21:33<00:35,  2.19it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1558/1635 [21:34<00:34,  2.23it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1559/1635 [21:34<00:33,  2.24it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1560/1635 [21:35<00:33,  2.25it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1561/1635 [21:35<00:33,  2.24it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1562/1635 [21:35<00:32,  2.24it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1563/1635 [21:36<00:32,  2.23it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1564/1635 [21:36<00:31,  2.25it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1565/1635 [21:37<00:31,  2.25it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1566/1635 [21:37<00:31,  2.20it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1567/1635 [21:38<00:30,  2.21it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1568/1635 [21:38<00:30,  2.18it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1569/1635 [21:39<00:30,  2.19it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1570/1635 [21:39<00:30,  2.11it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1571/1635 [21:40<00:30,  2.11it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1572/1635 [21:40<00:30,  2.09it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1573/1635 [21:41<00:30,  2.04it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1574/1635 [21:41<00:30,  2.03it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1575/1635 [21:42<00:28,  2.08it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1576/1635 [21:42<00:27,  2.13it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1577/1635 [21:42<00:26,  2.16it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1578/1635 [21:43<00:26,  2.15it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1579/1635 [21:43<00:25,  2.18it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1580/1635 [21:44<00:24,  2.21it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1581/1635 [21:44<00:24,  2.23it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1582/1635 [21:45<00:23,  2.24it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1583/1635 [21:45<00:23,  2.23it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1584/1635 [21:46<00:22,  2.24it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1585/1635 [21:46<00:22,  2.25it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1586/1635 [21:46<00:21,  2.27it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1587/1635 [21:47<00:21,  2.27it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1588/1635 [21:47<00:20,  2.26it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1589/1635 [21:48<00:20,  2.26it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1590/1635 [21:48<00:19,  2.27it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1591/1635 [21:49<00:19,  2.27it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1592/1635 [21:49<00:19,  2.26it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1593/1635 [21:50<00:18,  2.24it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1594/1635 [21:50<00:18,  2.20it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1595/1635 [21:51<00:18,  2.20it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1596/1635 [21:51<00:17,  2.19it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1597/1635 [21:51<00:17,  2.21it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1598/1635 [21:52<00:17,  2.17it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1599/1635 [21:52<00:16,  2.16it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1600/1635 [21:53<00:15,  2.19it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1601/1635 [21:53<00:15,  2.15it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1602/1635 [21:54<00:14,  2.20it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1603/1635 [21:54<00:14,  2.22it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1604/1635 [21:55<00:13,  2.24it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1605/1635 [21:55<00:13,  2.22it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1606/1635 [21:55<00:12,  2.23it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1607/1635 [21:56<00:12,  2.23it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1608/1635 [21:56<00:12,  2.24it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1609/1635 [21:57<00:11,  2.25it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1610/1635 [21:57<00:11,  2.25it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1611/1635 [21:58<00:10,  2.27it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1612/1635 [21:58<00:10,  2.28it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1613/1635 [21:59<00:09,  2.27it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1614/1635 [21:59<00:09,  2.27it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1615/1635 [21:59<00:08,  2.27it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1616/1635 [22:00<00:08,  2.26it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1617/1635 [22:00<00:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1618/1635 [22:01<00:07,  2.23it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1619/1635 [22:01<00:07,  2.22it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1620/1635 [22:02<00:06,  2.22it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1621/1635 [22:02<00:06,  2.22it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1622/1635 [22:03<00:05,  2.23it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1623/1635 [22:03<00:05,  2.20it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1624/1635 [22:04<00:04,  2.21it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1625/1635 [22:04<00:04,  2.24it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1626/1635 [22:04<00:04,  2.22it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1627/1635 [22:05<00:03,  2.22it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1628/1635 [22:05<00:03,  2.22it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1629/1635 [22:06<00:02,  2.13it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1630/1635 [22:06<00:02,  2.13it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1631/1635 [22:07<00:01,  2.17it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1632/1635 [22:07<00:01,  2.20it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1633/1635 [22:08<00:00,  2.16it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1634/1635 [22:08<00:00,  2.16it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1635/1635 [22:09<00:00,  2.25it/s]\u001b[0m\n",
      "\u001b[34m{'loss': 0.2756, 'learning_rate': 0.0, 'epoch': 5.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 1635/1635 [22:09<00:00,  2.25it/s]\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 82\n",
      "  Batch size = 2\u001b[0m\n",
      "\u001b[34mNum examples = 82\n",
      "  Batch size = 2\u001b[0m\n",
      "\u001b[34m0%|          | 0/41 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m5%|▍         | 2/41 [00:03<01:10,  1.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m7%|▋         | 3/41 [00:07<01:36,  2.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 4/41 [00:10<01:47,  2.90s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 5/41 [00:14<01:52,  3.12s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▍        | 6/41 [00:17<01:54,  3.26s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 7/41 [00:21<01:54,  3.37s/it]#033[A\u001b[0m\n",
      "\u001b[34m20%|█▉        | 8/41 [00:24<01:51,  3.38s/it]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 9/41 [00:28<01:50,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m24%|██▍       | 10/41 [00:31<01:46,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 11/41 [00:35<01:43,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▉       | 12/41 [00:38<01:38,  3.40s/it]#033[A\u001b[0m\n",
      "\u001b[34m32%|███▏      | 13/41 [00:41<01:35,  3.42s/it]#033[A\u001b[0m\n",
      "\u001b[34m34%|███▍      | 14/41 [00:45<01:32,  3.41s/it]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 15/41 [00:48<01:28,  3.41s/it]#033[A\u001b[0m\n",
      "\u001b[34m39%|███▉      | 16/41 [00:52<01:25,  3.41s/it]#033[A\u001b[0m\n",
      "\u001b[34m41%|████▏     | 17/41 [00:55<01:21,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 18/41 [00:58<01:18,  3.40s/it]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▋     | 19/41 [01:02<01:15,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m49%|████▉     | 20/41 [01:05<01:11,  3.40s/it]#033[A\u001b[0m\n",
      "\u001b[34m51%|█████     | 21/41 [01:09<01:08,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 22/41 [01:12<01:05,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 23/41 [01:16<01:01,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 24/41 [01:19<00:58,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m61%|██████    | 25/41 [01:23<00:55,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 26/41 [01:26<00:51,  3.46s/it]#033[A\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 27/41 [01:30<00:49,  3.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 28/41 [01:33<00:45,  3.51s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 29/41 [01:37<00:42,  3.51s/it]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 30/41 [01:40<00:38,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 31/41 [01:44<00:34,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 32/41 [01:47<00:30,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m80%|████████  | 33/41 [01:50<00:27,  3.41s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 34/41 [01:54<00:24,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 35/41 [01:57<00:20,  3.42s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 36/41 [02:01<00:17,  3.40s/it]#033[A\u001b[0m\n",
      "\u001b[34m90%|█████████ | 37/41 [02:04<00:13,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 38/41 [02:08<00:10,  3.46s/it]#033[A\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 39/41 [02:11<00:06,  3.46s/it]#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 40/41 [02:14<00:03,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 41/41 [02:18<00:00,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4506534934043884, 'eval_rouge1': 46.9113, 'eval_rouge2': 30.2136, 'eval_rougeL': 34.2383, 'eval_rougeLsum': 34.3438, 'eval_gen_len': 80.2439, 'eval_runtime': 143.111, 'eval_samples_per_second': 0.573, 'eval_steps_per_second': 0.286, 'epoch': 5.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 1635/1635 [24:32<00:00,  2.25it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 41/41 [02:19<00:00,  3.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-1635\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-1635\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-1635/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-1635/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-1635/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-1635/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-1635/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-1635/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-1635/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-1635/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mDeleting older checkpoint [/opt/ml/model/checkpoint-654] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34mDeleting older checkpoint [/opt/ml/model/checkpoint-654] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from /opt/ml/model/checkpoint-1635 (score: 30.2136).\u001b[0m\n",
      "\u001b[34mLoading best model from /opt/ml/model/checkpoint-1635 (score: 30.2136).\u001b[0m\n",
      "\u001b[34m{'train_runtime': 1474.8987, 'train_samples_per_second': 5.533, 'train_steps_per_second': 1.109, 'train_loss': 0.5549735579651065, 'epoch': 5.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 1635/1635 [24:34<00:00,  2.25it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1635/1635 [24:34<00:00,  1.11it/s]\u001b[0m\n",
      "\u001b[34mModel trained successfully\u001b[0m\n",
      "\u001b[34mINFO:__main__:Model trained successfully\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mModel saved successfully\u001b[0m\n",
      "\u001b[34m*** Evaluate on test set***\u001b[0m\n",
      "\u001b[34mINFO:__main__:Model saved successfully\u001b[0m\n",
      "\u001b[34mINFO:__main__:*** Evaluate on test set***\u001b[0m\n",
      "\u001b[34mThe following columns in the test set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the test set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: Summary, __index_level_0__, token_type_ids, Article. If Summary, __index_level_0__, token_type_ids, Article are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m***** Running Prediction *****\u001b[0m\n",
      "\u001b[34m***** Running Prediction *****\u001b[0m\n",
      "\u001b[34mNum examples = 326\n",
      "  Batch size = 2\u001b[0m\n",
      "\u001b[34mNum examples = 326\n",
      "  Batch size = 2\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:531: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\u001b[0m\n",
      "\u001b[34m0%|          | 0/163 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 2/163 [00:03<04:55,  1.84s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 3/163 [00:07<06:53,  2.58s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 4/163 [00:10<07:42,  2.91s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 5/163 [00:14<08:09,  3.10s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 6/163 [00:17<08:32,  3.26s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 7/163 [00:21<08:43,  3.35s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 8/163 [00:24<08:47,  3.40s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 9/163 [00:28<08:45,  3.41s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 10/163 [00:31<08:53,  3.49s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 11/163 [00:35<08:48,  3.47s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 12/163 [00:39<08:50,  3.51s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 13/163 [00:42<08:46,  3.51s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 14/163 [00:46<08:52,  3.58s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 15/163 [00:49<08:40,  3.52s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 16/163 [00:52<08:30,  3.47s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 17/163 [00:56<08:20,  3.43s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 18/163 [01:00<08:31,  3.53s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 19/163 [01:03<08:35,  3.58s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 20/163 [01:07<08:28,  3.56s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 21/163 [01:10<08:28,  3.58s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 22/163 [01:14<08:22,  3.56s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 23/163 [01:17<08:18,  3.56s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 24/163 [01:21<08:11,  3.53s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 25/163 [01:25<08:07,  3.54s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 26/163 [01:28<08:03,  3.53s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 27/163 [01:31<07:56,  3.50s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 28/163 [01:35<07:48,  3.47s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 29/163 [01:38<07:41,  3.45s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 30/163 [01:42<07:34,  3.42s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 31/163 [01:45<07:30,  3.41s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 32/163 [01:48<07:25,  3.40s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 33/163 [01:52<07:21,  3.40s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 34/163 [01:55<07:18,  3.40s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 35/163 [01:59<07:26,  3.49s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 36/163 [02:03<07:32,  3.56s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 37/163 [02:06<07:22,  3.51s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 38/163 [02:09<07:17,  3.50s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 39/163 [02:13<07:18,  3.54s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 40/163 [02:17<07:11,  3.51s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 41/163 [02:20<07:07,  3.50s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 42/163 [02:24<07:06,  3.52s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 43/163 [02:27<06:59,  3.50s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 44/163 [02:30<06:52,  3.47s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 45/163 [02:34<06:51,  3.48s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 46/163 [02:38<06:50,  3.51s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 47/163 [02:41<06:48,  3.52s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 48/163 [02:44<06:41,  3.49s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 49/163 [02:48<06:35,  3.47s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 50/163 [02:51<06:30,  3.46s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 51/163 [02:55<06:24,  3.43s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 52/163 [02:58<06:21,  3.44s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 53/163 [03:02<06:30,  3.55s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 54/163 [03:05<06:21,  3.50s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 55/163 [03:09<06:13,  3.46s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 56/163 [03:12<06:07,  3.43s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 57/163 [03:15<06:02,  3.42s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 58/163 [03:19<05:56,  3.39s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 59/163 [03:22<05:53,  3.40s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 60/163 [03:26<05:53,  3.43s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 61/163 [03:29<05:49,  3.42s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 62/163 [03:33<05:45,  3.42s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 63/163 [03:36<05:41,  3.41s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 64/163 [03:39<05:36,  3.39s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 65/163 [03:43<05:36,  3.44s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 66/163 [03:46<05:32,  3.43s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 67/163 [03:50<05:29,  3.43s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 68/163 [03:53<05:23,  3.41s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 69/163 [03:56<05:19,  3.40s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 70/163 [04:00<05:21,  3.45s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 71/163 [04:04<05:23,  3.51s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 72/163 [04:07<05:16,  3.48s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 73/163 [04:10<05:10,  3.45s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 74/163 [04:14<05:08,  3.47s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 75/163 [04:17<05:02,  3.44s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 76/163 [04:21<04:57,  3.41s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 77/163 [04:24<04:57,  3.46s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 78/163 [04:28<04:52,  3.44s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 79/163 [04:31<04:47,  3.42s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 80/163 [04:34<04:44,  3.43s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 81/163 [04:38<04:39,  3.41s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 82/163 [04:41<04:35,  3.40s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 83/163 [04:45<04:31,  3.40s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 84/163 [04:48<04:30,  3.42s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 85/163 [04:51<04:25,  3.40s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 86/163 [04:55<04:24,  3.43s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 87/163 [04:59<04:24,  3.48s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 88/163 [05:02<04:25,  3.54s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 89/163 [05:06<04:21,  3.54s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 90/163 [05:09<04:14,  3.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 91/163 [05:13<04:10,  3.48s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 92/163 [05:16<04:03,  3.44s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 93/163 [05:19<03:59,  3.42s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 94/163 [05:23<03:54,  3.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 95/163 [05:26<03:53,  3.43s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 96/163 [05:30<03:50,  3.44s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 97/163 [05:33<03:46,  3.44s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 98/163 [05:36<03:41,  3.40s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 99/163 [05:40<03:39,  3.42s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 100/163 [05:43<03:35,  3.42s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 101/163 [05:47<03:32,  3.42s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 102/163 [05:50<03:29,  3.43s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 103/163 [05:54<03:28,  3.47s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 104/163 [05:57<03:26,  3.49s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 105/163 [06:01<03:26,  3.56s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 106/163 [06:04<03:20,  3.51s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 107/163 [06:08<03:19,  3.57s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 108/163 [06:11<03:12,  3.50s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 109/163 [06:15<03:09,  3.50s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 110/163 [06:19<03:08,  3.55s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 111/163 [06:22<03:01,  3.49s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 112/163 [06:25<02:56,  3.47s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 113/163 [06:29<02:55,  3.52s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 114/163 [06:32<02:50,  3.49s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 115/163 [06:36<02:46,  3.48s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 116/163 [06:39<02:44,  3.50s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 117/163 [06:43<02:38,  3.45s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 118/163 [06:46<02:34,  3.44s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 119/163 [06:49<02:29,  3.40s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 120/163 [06:53<02:26,  3.40s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 121/163 [06:56<02:22,  3.39s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 122/163 [07:00<02:20,  3.42s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 123/163 [07:03<02:18,  3.46s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 124/163 [07:07<02:14,  3.44s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 125/163 [07:10<02:09,  3.42s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 126/163 [07:13<02:06,  3.43s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 127/163 [07:17<02:04,  3.45s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 128/163 [07:20<02:01,  3.47s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 129/163 [07:24<01:57,  3.46s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 130/163 [07:27<01:53,  3.45s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 131/163 [07:31<01:52,  3.51s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 132/163 [07:34<01:48,  3.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 133/163 [07:38<01:44,  3.47s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 134/163 [07:41<01:42,  3.52s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 135/163 [07:45<01:38,  3.52s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 136/163 [07:48<01:34,  3.50s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 137/163 [07:52<01:30,  3.48s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 138/163 [07:55<01:26,  3.46s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 139/163 [07:59<01:25,  3.54s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 140/163 [08:03<01:23,  3.64s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 141/163 [08:06<01:19,  3.60s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 142/163 [08:10<01:15,  3.60s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 143/163 [08:14<01:12,  3.60s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 144/163 [08:17<01:07,  3.58s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 145/163 [08:21<01:04,  3.57s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 146/163 [08:24<01:01,  3.59s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 147/163 [08:28<00:57,  3.60s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 148/163 [08:32<00:53,  3.59s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 149/163 [08:35<00:49,  3.53s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 150/163 [08:38<00:45,  3.53s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 151/163 [08:42<00:41,  3.48s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 152/163 [08:45<00:38,  3.51s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 153/163 [08:49<00:35,  3.50s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 154/163 [08:53<00:32,  3.56s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 155/163 [08:56<00:28,  3.55s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 156/163 [09:00<00:24,  3.54s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 157/163 [09:03<00:21,  3.61s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 158/163 [09:07<00:18,  3.61s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 159/163 [09:10<00:14,  3.56s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 160/163 [09:14<00:10,  3.56s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 161/163 [09:18<00:07,  3.59s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 162/163 [09:21<00:03,  3.56s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 163/163 [09:25<00:00,  3.54s/it]\u001b[0m\n",
      "\u001b[34mPredictionOutput(predictions=array([[  101,  1996,  2396, ...,     0,     0,     0],\n",
      "       [  101,  6983,  3036, ...,     0,     0,     0],\n",
      "       [  101,  1045,  2245, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  101,  5796, 14072, ...,     0,     0,     0],\n",
      "       [  101,  4572,  4557, ...,     0,     0,     0],\n",
      "       [  101,  1996,  1051, ...,     0,     0,     0]]), label_ids=array([[  101,  2172,  1997, ...,     0,     0,     0],\n",
      "       [  101,  1996,  2047, ...,     0,     0,     0],\n",
      "       [  101, 12082, 16455, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  101,  1037,  7160, ...,     0,     0,     0],\n",
      "       [  101,  2928,  4572, ...,     0,     0,     0],\n",
      "       [  101,  2035,  2752, ...,     0,     0,     0]]), metrics={'test_loss': 0.470162034034729, 'test_rouge1': 48.7492, 'test_rouge2': 32.1673, 'test_rougeL': 35.028, 'test_rougeLsum': 35.1087, 'test_gen_len': 80.4264, 'test_runtime': 572.0278, 'test_samples_per_second': 0.57, 'test_steps_per_second': 0.285})\u001b[0m\n",
      "\u001b[34mINFO:__main__:PredictionOutput(predictions=array([[  101,  1996,  2396, ...,     0,     0,     0],\n",
      "       [  101,  6983,  3036, ...,     0,     0,     0],\n",
      "       [  101,  1045,  2245, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  101,  5796, 14072, ...,     0,     0,     0],\n",
      "       [  101,  4572,  4557, ...,     0,     0,     0],\n",
      "       [  101,  1996,  1051, ...,     0,     0,     0]]), label_ids=array([[  101,  2172,  1997, ...,     0,     0,     0],\n",
      "       [  101,  1996,  2047, ...,     0,     0,     0],\n",
      "       [  101, 12082, 16455, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  101,  1037,  7160, ...,     0,     0,     0],\n",
      "       [  101,  2928,  4572, ...,     0,     0,     0],\n",
      "       [  101,  2035,  2752, ...,     0,     0,     0]]), metrics={'test_loss': 0.470162034034729, 'test_rouge1': 48.7492, 'test_rouge2': 32.1673, 'test_rougeL': 35.028, 'test_rougeLsum': 35.1087, 'test_gen_len': 80.4264, 'test_runtime': 572.0278, 'test_samples_per_second': 0.57, 'test_steps_per_second': 0.285})\u001b[0m\n",
      "\u001b[34mRemoving unused checkpoints to save space in container\u001b[0m\n",
      "\u001b[34mINFO:__main__:Removing unused checkpoints to save space in container\u001b[0m\n",
      "\u001b[34m100%|██████████| 163/163 [09:28<00:00,  3.49s/it]\u001b[0m\n",
      "\u001b[34m2022-07-03 12:23:34,232 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-07-03 12:24:40 Uploading - Uploading generated training model\n",
      "2022-07-03 12:27:16 Completed - Training job completed\n",
      "ProfilerReport-1656848501: IssuesFound\n",
      "Training seconds: 2611\n",
      "Billable seconds: 2611\n"
     ]
    }
   ],
   "source": [
    "model=model_invoke(model_name=model_names,train_test_val_location_S3=train_test_val_location_S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {j:model_dict[j].model_data for i,j in enumerate(model_dict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e3d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "model_name = \"bert2bert_cnn_daily_mail\"\n",
    "# Enter final location of your Model\n",
    "model_location=f\"s3://{Bucket_Name}/final_models/\"+model_name+\".tar.gz\"\n",
    "\n",
    "model_for_deployment = HuggingFaceModel(\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"Utilities\",\n",
    "    model_data=model_location,\n",
    "    role=role,\n",
    "    pytorch_version=\"1.7.1\",\n",
    "    py_version=\"py36\",\n",
    "    transformers_version=\"4.6.1\",\n",
    "    name=model_name.replace(r\"_\",\"-\")+\"-V2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1bbb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"summarization-endpoint-5\"+model_name+\"-1\"\n",
    "\n",
    "predictor = model_for_deployment.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    endpoint_name=endpoint_name.replace(r\"_\",\"-\"),\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecfd2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict({\n",
    "'inputs': \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0368c6d5",
   "metadata": {},
   "source": [
    "### Average first loading time 2 Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5243a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can opt for Async inferencing for higher load\n",
    "# from sagemaker.async_inference import AsyncInferenceConfig\n",
    "# prefix=\"async-location\"\n",
    "# endpoint_name = \"summarization-endpoint-5\"+model_name+\"-async-V1\"\n",
    "# # Create an empty AsyncInferenceConfig object to use default values\n",
    "# async_config = AsyncInferenceConfig(output_path=f\"s3://{Bucket_Name}/{prefix}/output\")\n",
    "\n",
    "# # deploy model to SageMaker Inference\n",
    "# async_predictor = model_for_deployment.deploy(\n",
    "#     async_inference_config=async_config,\n",
    "#     initial_instance_count=1, # number of instances\n",
    "#     instance_type='ml.g4dn.xlarge', # instance type,\n",
    "#     serializer=sagemaker.serializers.JSONSerializer(),\n",
    "#     deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    "#     endpoint_name=endpoint_name.replace(r\"_\",\"-\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async_predictor.predict_async({\n",
    "# 'inputs': \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf59365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96806486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
